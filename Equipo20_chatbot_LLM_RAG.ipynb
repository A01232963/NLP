{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hVND8xY2OKY"
   },
   "source": [
    "# **Procesamiento de Lenguaje Natural**\n",
    "\n",
    "## Maestr√≠a en Inteligencia Artificial Aplicada\n",
    "#### Tecnol√≥gico de Monterrey\n",
    "#### Prof Luis Eduardo Falc√≥n Morales\n",
    "\n",
    "### **Adtividad en Equipos: sistema LLM + RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aimHVFOv23lm"
   },
   "source": [
    "* **Nombres y matr√≠culas:**\n",
    "\n",
    "* üßë‚Äçüíª Ovidio Alejandro Hern√°ndez Ruano (A01796714)\n",
    "* üßë‚Äçüíª Jos√© Manuel Toral Cruz (A01122243)\n",
    "* üßë‚Äçüíª Oscar Enrique Garc√≠a Garc√≠a (A01016093)\n",
    "* üßë‚Äçüíª Luis Gerardo Sanchez Salazar (A01232963)\n",
    "\n",
    "* **N√∫mero de Equipo:**\n",
    "* Equipo #20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jimvsiVgjMg"
   },
   "source": [
    "* ##### **El formato de este cuaderno de Jupyter es libre, pero debe incuir al menos las siguientes secciones:**\n",
    "\n",
    "  * ##### **Introducci√≥n de la problem√°tica a resolver.**\n",
    "  * ##### **Sistema RAG + LLM**\n",
    "  * ##### **El chatbot, incluyendo ejemplos de prueba.**\n",
    "  * ##### **Conclusiones**\n",
    "\n",
    "* ##### **Pueden importar los paquetes o librer√≠as que requieran.**\n",
    "\n",
    "* ##### **Pueden incluir las celdas y l√≠neas de c√≥digo que deseen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2akzn895aF_"
   },
   "source": [
    "# **Introducci√≥n de la problem√°tica a resolver.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq3bI2BBBm97"
   },
   "source": [
    "## üí° Ansiedad y depresi√≥n: Falta de acceso inmediato, confiable y seguro a informaci√≥n\n",
    "\n",
    "**La ansiedad y la depresi√≥n** son dos de los transtornos de salud mental m√°s comunes a nivel mundial, afectando a millones de personas de todas las edades. (Hohls et al., 2021) A pesar de su prevalencia, muchas personas no cuentan con acceso oportuno a informaci√≥n clara, comprensible y basada en evidencia que les permita entender sus s√≠ntomas, buscar ayuda o simplemente sentirse acompa√±adas en su proceso.\n",
    "\n",
    "Factores como la estigma social, la desinformaci√≥n, las barreras econ√≥micas, la escasez de profesionales en salud mental y largos tiempos de espera para recibir atenci√≥n dificultan quee quienes sufren de estos trastornos obtengan orientaci√≥n adecuada. Adem√°s, en entornos digitales sobrecargados de contenido, es frecuente encontrar informaci√≥n err√≥nea, poco √∫til o incluso perjudicial (Hua et al., 2025).\n",
    "\n",
    "En este contexto, se propone el desarrollo de un **chatbot** especializado en ansiedad y depresi√≥n, que brinde respuestas confiables, emp√°ticas y accesibles. Este asistente digital tiene como objetivo reducir la brecha de informaci√≥n, orientar a las personas hacia recursos apropiados y contribuir al bienestar emocional desde un enfoque preventivo y educativo.\n",
    "\n",
    "Para el desarrollo del chatbot, se usar√° Retrieval-Augmented Generation (**RAG**) en combinaci√≥n de modelos de lenguaje de gran escala (**LLM**), generando as√≠ una soluci√≥n efectiva, principalmente por las siguientes razones:\n",
    "\n",
    "* ‚úÖ **Actualizaci√≥n y precisi√≥n sobre el contenido:** RAG permite que el modelo no genere respuestas aleatorias basadas en su entrenamiento previo, sino que consulte una base documental curada como gu√≠as cl√≠nicas, material psicoeducativo validado, publicaciones cient√≠ficas, o preguntas frecuentes verificadas, reduciendo el riesgo de respuestas incorrectas o no fundamentadas, lo cual es crucial al tratar temas sensibles como la salud mental.\n",
    "\n",
    "* ‚úÖ **Actualizaci√≥n din√°mica y adaptabilidad**: A diferencia de un LLM puro, que no puede aprender nueva informaci√≥n tras su entrenamiento, un sistema RAG puede actualizar f√°cilmente su corpus de conocimiento sin necesidad de reentrenamiento. As√≠, el chatbot puede mantenerse actualizado con las √∫ltimas recomendaciones cl√≠nicas, normativas locales o recursos disponibles (como l√≠neas de ayuda o centros de atenci√≥n comunitarios) o incluso, diagn√≥sticos, conversaciones, o historiales cl√≠nicos del paciente para una experiencia m√°s personalizada.\n",
    "\n",
    "* ‚úÖ **Respuestas contextuales, emp√°ticas y comprensibles**: El LLM permite que las respuestas se generen en lenguaje natural, adaptadas al tono del usuario, con un estilo conversacional emp√°tico y accesible. Esto ayuda a que las personas se sientan comprendidas y no juzgadas, y que la informaci√≥n se transmita con claridad y calidez (Palomares, 2024).\n",
    "\n",
    "* ‚úÖ **Escalabilidad y disponibilidad**: Al ser una soluci√≥n automatizada, el chatbot puede estar disponible 24/7, sin importar la zona horaria ni la demanda, lo que permite llegar a m√°s personas en momentos de urgencia o duda. Esto lo convierte en una herramienta valiosa en comunidades con recursos limitados (AWS, 2025).\n",
    "\n",
    "* ‚úÖ **Privacidad y anonimato**: Muchos usuarios prefieren explorar sus dudas sobre salud mental de forma an√≥nima, sin tener que hablar cara a cara con un profesional desde el inicio. Un chatbot con estas caracter√≠sticas ofrece un espacio seguro, privado y no intrusivo donde dar los primeros pasos hacia el autocuidado o la b√∫squeda de ayuda (Hua et al., 2025).\n",
    "\n",
    "Combinar RAG + LLM para desarrollar un chatbot sobre ansiedad y depresi√≥n no solo mejora la calidad y seguridad de las respuestas, sino que adem√°s ofrece una soluci√≥n t√©cnica √©tica, escalable y centrada en el bienestar del usuario. Esta herramienta no pretende reemplazar el acompa√±amiento profesional, sino funcionar como una gu√≠a accesible, informada y confiable que ayude a reducir barreras, brindar contenci√≥n y facilitar el acceso a recursos de salud mental adecuados.\n",
    "\n",
    "A continuaci√≥n se presenta una propuesta desarrollada con **fines exclusivamente educativos**. Por ello, las respuestas generadas deben ser interpretadas como orientaciones generales y no deben considerarse asesoramiento m√©dico, diagn√≥stico cl√≠nico ni sustituto de atenci√≥n profesional. Se recomienda que los usuarios consulten a especialistas en salud mental ante cualquier duda o situaci√≥n que requiera intervenci√≥n profesional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQL0S7wX54Vh"
   },
   "source": [
    "# **Paquetes y librer√≠as**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmeyvDTjBGHV"
   },
   "source": [
    "## üîç Procesamiento de Lenguaje Natural (NLP)\n",
    "* **üìö transformers:**  Biblioteca de modelos preentrenados desarrollada por Hugging Face. Permite usar modelos de NLP como BERT, GPT, T5, etc., para tareas como clasificaci√≥n, resumen, traducci√≥n, y m√°s.\n",
    "\n",
    "* **üß† sentence-transformers:** Extensi√≥n sobre transformers enfocada en generar representaciones vectoriales (embeddings) de oraciones y p√°rrafos. Ideal para tareas como b√∫squeda sem√°ntica, comparaci√≥n de textos y clustering.\n",
    "\n",
    "* **üìä datasets:** Colecci√≥n de datasets estandarizados de Hugging Face para NLP. Simplifica la carga, preprocesamiento y uso de datos para entrenamiento y evaluaci√≥n de modelos.\n",
    "\n",
    "## üì¶ Vectorizaci√≥n y B√∫squeda Sem√°ntica\n",
    "* **üß≠ faiss-cpu:** Biblioteca de b√∫squeda eficiente de vectores desarrollada por Facebook AI. Se usa para encontrar r√°pidamente los elementos m√°s cercanos en grandes conjuntos de embeddings.\n",
    "\n",
    "## üñºÔ∏è Interfaz de Usuario / Aplicaciones Web\n",
    "* **üß™ gradio:**\n",
    " Herramienta para crear interfaces web r√°pidas y simples para modelos de machine learning. Ideal para prototipar y compartir modelos con inputs y outputs interactivos, lo cu√°l es perfecto para el Chatbot a desarrollar.\n",
    "\n",
    "## üìÑ Lectura de Documentos PDF\n",
    "* **üìÑ PyMuPDF:** Biblioteca para leer, extraer texto y trabajar con archivos PDF y otros documentos. Muy √∫til para convertir PDFs a texto para an√°lisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVMo8aNh595N",
    "outputId": "a056a72f-ea79-4946-8456-040ed2809c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.1\n"
     ]
    }
   ],
   "source": [
    "# Incluyan a continuaci√≥n todas las celdas (de c√≥digo o texto) que deseen...\n",
    "!pip install transformers\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install gradio\n",
    "!pip install datasets\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJtWHl5iBMpo"
   },
   "source": [
    "## üß± Utilidades del Sistema y Datos\n",
    "\n",
    "* **üìÇ os:** M√≥dulo est√°ndar de Python para interactuar con el sistema operativo. Se usa para operaciones como navegar entre carpetas, crear directorios o manipular archivos.\n",
    "\n",
    "* **üì¶ pickle:** Biblioteca est√°ndar de Python para serializar y deserializar objetos. √ötil para guardar modelos, datos procesados o estructuras en archivos binarios para reutilizaci√≥n.\n",
    "\n",
    "* **üî¢ numpy:** Paquete fundamental para computaci√≥n num√©rica en Python. Permite manejar arrays y realizar operaciones matem√°ticas eficientes a nivel de matriz.\n",
    "\n",
    "* **üåé IPython.display:** Importamos las funciones `display` y `HTML` para desplegar contenido enriquecido como HTML dentro de celdas de Google Colab.\n",
    "\n",
    "* **üî° re:** M√≥dulo de expresiones regulares en Python. Se usa para buscar, reemplazar o dividir texto mediante patrones definidos.\n",
    "\n",
    "## üìÑ Procesamiento de Documentos PDF\n",
    "\n",
    "* **üìÑ fitz (PyMuPDF):** Interfaz principal de la biblioteca PyMuPDF. Permite abrir, leer y extraer texto o im√°genes de archivos PDF y otros documentos.\n",
    "\n",
    "## üì¶ B√∫squeda Sem√°ntica\n",
    "\n",
    "* **üß≠ faiss:** Biblioteca de Facebook AI para b√∫squeda r√°pida de vectores en grandes vol√∫menes de datos. Se usa para tareas de similitud sem√°ntica y recuperaci√≥n de informaci√≥n basada en embeddings.\n",
    "\n",
    "## üîç Procesamiento de Lenguaje Natural (NLP)\n",
    "\n",
    "* **üß† sentence-transformers:** Biblioteca que permite generar embeddings sem√°nticos de textos. Generalmente utilizada para tareas como clustering, recuperaci√≥n sem√°ntica y comparaci√≥n de oraciones.\n",
    "\n",
    "* **üß¨ transformers (AutoTokenizer, AutoModelForSeq2SeqLM, pipeline):** Componentes clave de la librer√≠a Hugging Face Transformers:\n",
    "  - **AutoTokenizer:** Convierte texto a tokens entendibles por modelos.\n",
    "  - **AutoModelForSeq2SeqLM:** Carga modelos preentrenados para tareas de secuencia a secuencia.\n",
    "  - **pipeline:** Interfaz simplificada para aplicar tareas comunes con modelos preentrenados.\n",
    "\n",
    "* **üó£Ô∏è nltk & sent_tokenize:** `nltk` es una biblioteca para procesamiento de lenguaje natural. En este caso, se utiliza para **tokenizar texto en oraciones** mediante `sent_tokenize`, √∫til para dividir grandes textos en unidades m√°s manejables.\n",
    "\n",
    "## üìê Normalizaci√≥n de Vectores\n",
    "\n",
    "* **üìê normalize:** Se utiliza para escalar vectores de forma que tengan una norma unitaria. Es esencial para calcular similitudes de forma coherente entre vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2KsDfQ0BUh_",
    "outputId": "611cb3b9-2628-4ae8-f403-142d27ab9e1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from IPython.display import display, HTML\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tthhwfJhBo0o"
   },
   "source": [
    "## üìÇ Archivos PDF y sus descripciones\n",
    "\n",
    "A continuaci√≥n se enlistan los archivos a utilizar para el chatbot, junto con su tema principal y una berve descripci√≥n de su conrtenido.\n",
    "\n",
    "**1. empatia_comunicacion.pdf**\n",
    "* Tema: Empat√≠a en la comunicaci√≥n\n",
    "* Descripci√≥n: Describe el concepto de empat√≠a desde el punto de vista cognitivo y emocional, destacando la importancia de las neuronas espejo y c√≥mo la empat√≠a mejora la calidad de la comunicaci√≥n interpersonal. Incluye t√©cnicas como la escucha activa, actitud de apertura y rechazo de prejuicios\n",
    "\n",
    "\n",
    "**2. primeras-paginas-lo-mejor-de-tu-vida-es.pdf**\n",
    "* Tema: Autoestima y confianza personal\n",
    "* Descripci√≥n: Fragmento del libro de Ma. Jes√∫s √Ålava Reyes. Enfatiza la importancia de confiar en uno mismo para alcanzar la felicidad. Incluye reflexiones, testimonios y cap√≠tulos orientados al desarrollo de la autoconfianza y la superaci√≥n del sufrimiento emocional\n",
    "\n",
    "\n",
    "**3. Guia de Primeros Auxilios Psicol√≥gicos_Integra.pdf**\n",
    "* Tema: Primeros Auxilios Psicol√≥gicos (PAP)\n",
    "* Descripci√≥n: Gu√≠a orientada a personas en movilidad humana. Explica qu√© es una crisis psicol√≥gica, c√≥mo se manifiesta, tipos de intervenci√≥n, principios del PAP, y autocuidado del personal interviniente. Incluye t√©cnicas como escucha emp√°tica, estabilizaci√≥n y contenci√≥n emocional\n",
    "\n",
    "\n",
    "**4. depresion.pdf**\n",
    "* Tema: Depresi√≥n\n",
    "* Descripci√≥n: Documento del National Institute of Mental Health. Define la depresi√≥n, sus s√≠ntomas, causas, tipos (mayor, distimia, estacional, posparto, etc.), diagn√≥stico y tratamientos (psicoterapia, medicamentos, terapia de estimulaci√≥n cerebral)\n",
    "\n",
    "\n",
    "**5. Abre-tu-mente-modo-positivo-salud-mental.pdf**\n",
    "* Tema: Promoci√≥n de salud mental en j√≥venes\n",
    "* Descripci√≥n: Gu√≠a educativa dirigida a docentes y familias. Aborda temas como salud mental, adolescencia, estilo de vida saludable, relaciones sociales, emociones, inteligencia emocional y prevenci√≥n de problemas de salud mental.\n",
    "\n",
    "\n",
    "**6. AtencionPrimAmb1988_spa.pdf**\n",
    "* Tema: Atenci√≥n Primaria Ambiental (APA)\n",
    "* Descripci√≥n: Publicaci√≥n de la OPS que presenta el concepto de APA. Ofrece un enfoque hol√≠stico para mejorar el ambiente y la salud p√∫blica. Incluye marco conceptual, principios, problemas ambientales locales, participaci√≥n ciudadana y organizaci√≥n de centros APA\n",
    "\n",
    "\n",
    "**7. 9789243548203_spa.pdf**\n",
    "* Tema: Primera Ayuda Psicol√≥gica (OMS)\n",
    "* Descripci√≥n: Gu√≠a pr√°ctica para trabajadores de campo en situaciones de emergencia. Define PAP, principios de acci√≥n (observar, escuchar, conectar), c√≥mo ayudar de forma responsable y c√≥mo cuidarse como interviniente. Incluye ejercicios y casos simulados\n",
    "\n",
    "\n",
    "**8. empatia.pdf**\n",
    "* Tema: Empat√≠a y neurociencia\n",
    "* Descripci√≥n: Presentaci√≥n sobre empat√≠a desde una perspectiva emocional, cognitiva y neurocient√≠fica.\n",
    "\n",
    "\n",
    "**9. Guiasautoayudadepresionansiedad.pdf**\n",
    "* Tema: Autoayuda para depresi√≥n y ansiedad\n",
    "* Descripci√≥n: Conjunto de gu√≠as del Servicio Andaluz de Salud. Contienen informaci√≥n y actividades sobre depresi√≥n, ansiedad, duelo, autoestima, control de pensamientos, t√©cnicas de relajaci√≥n, afrontamiento del estr√©s, etc√©rtera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muh29EoTYcDI"
   },
   "source": [
    "## üìÅ Creaci√≥n de Carpeta y Descarga Condicional de Archivos\n",
    "\n",
    "Este bloque de c√≥digo verifica si existe una carpeta llamada `pdf` en el entorno (`/content/pdf`) y realiza las siguientes acciones:\n",
    "\n",
    "* üóÇÔ∏è **Crea la carpeta si no existe**, asegurando el espacio necesario para almacenar los archivos PDF.\n",
    "* üîç **Verifica si la carpeta est√° vac√≠a**:\n",
    "  - Si est√° vac√≠a, **descarga los archivos desde una carpeta p√∫blica en Google Drive** usando `gdown`.\n",
    "  - Si ya contiene archivos, **omite la descarga** para evitar redundancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD_iRBEQcHj9",
    "outputId": "bc4a4055-5de1-4058-fc33-f812f2607667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Carpeta creada: /content/pdf\n",
      "üì• La carpeta est√° vac√≠a. Iniciando descarga de contenidos...\n",
      "Retrieving folder contents\n",
      "Processing file 1RqMKjObfW74KOjsigrp5yEGyfQ7CHhqc AtencionPrimAmb1988_spa.pdf\n",
      "Processing file 1yGMaILcMOQmZYkLu0vys0deRj5dqt7UP primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf\n",
      "Processing file 1Xjx71RvGUBeujBbI8UKlqrQmq7YHm-ta Abre-tu-mente-modo-positivo-salud-mental.pdf\n",
      "Processing file 1Yg0JTjMj6UWECVpuOBlB13zMm9pid-J0 Guia de Primeros Auxilios PsicoloÃÅgicos_Integra.pdf\n",
      "Processing file 1kG5IIlGvSiQ0ssXATpeObGRZbFwf58QP 9789243548203_spa.pdf\n",
      "Processing file 1hRSuv2xQ5BurzmlZylc3zB7YzgtWaAil Guiasautoayudadepresionansiedad.pdf\n",
      "Processing file 1RY6Te6pvkc_4YpVYnbUBvm___1gpdoH6 depresion.pdf\n",
      "Processing file 1wmn6s6ydyh23PFVIdr1UsaQoJDXO7ouk empatia.pdf\n",
      "Processing file 1G-pEX_H2UXOZitt7cfjTLZgEAnDmfFIe empatia_comunicacion.pdf\n",
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RqMKjObfW74KOjsigrp5yEGyfQ7CHhqc\n",
      "To: /content/pdf/AtencionPrimAmb1988_spa.pdf\n",
      "100% 5.19M/5.19M [00:00<00:00, 20.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yGMaILcMOQmZYkLu0vys0deRj5dqt7UP\n",
      "To: /content/pdf/primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf\n",
      "100% 161k/161k [00:00<00:00, 93.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Xjx71RvGUBeujBbI8UKlqrQmq7YHm-ta\n",
      "To: /content/pdf/Abre-tu-mente-modo-positivo-salud-mental.pdf\n",
      "100% 3.82M/3.82M [00:00<00:00, 27.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yg0JTjMj6UWECVpuOBlB13zMm9pid-J0\n",
      "To: /content/pdf/Guia de Primeros Auxilios PsicoloÃÅgicos_Integra.pdf\n",
      "100% 941k/941k [00:00<00:00, 119MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1kG5IIlGvSiQ0ssXATpeObGRZbFwf58QP\n",
      "To: /content/pdf/9789243548203_spa.pdf\n",
      "100% 5.17M/5.17M [00:00<00:00, 20.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hRSuv2xQ5BurzmlZylc3zB7YzgtWaAil\n",
      "To: /content/pdf/Guiasautoayudadepresionansiedad.pdf\n",
      "100% 21.5M/21.5M [00:00<00:00, 42.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RY6Te6pvkc_4YpVYnbUBvm___1gpdoH6\n",
      "To: /content/pdf/depresion.pdf\n",
      "100% 2.81M/2.81M [00:00<00:00, 72.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wmn6s6ydyh23PFVIdr1UsaQoJDXO7ouk\n",
      "To: /content/pdf/empatia.pdf\n",
      "100% 23.6M/23.6M [00:00<00:00, 33.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1G-pEX_H2UXOZitt7cfjTLZgEAnDmfFIe\n",
      "To: /content/pdf/empatia_comunicacion.pdf\n",
      "100% 195k/195k [00:00<00:00, 78.2MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "# Crear la carpeta \"pdf\" si es que no existe\n",
    "folder_path = \"/content/pdf\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"‚úÖ Carpeta creada: {folder_path}\")\n",
    "else:\n",
    "    print(f\"üìÅ La carpeta ya existe: {folder_path}\")\n",
    "\n",
    "# Revisar si la carpeta est√° vac√≠a y descargar los archivos de la misma. Si no, saltar descarga.\n",
    "if not os.listdir(folder_path):\n",
    "    print(\"üì• La carpeta est√° vac√≠a. Iniciando descarga de contenidos...\")\n",
    "    folder_url = \"https://drive.google.com/drive/folders/1WxKzp5YHdhS4hf47zFUScL9FHpRSaexE?usp=sharing\"\n",
    "    !gdown --folder {folder_url} -O {folder_path}\n",
    "else:\n",
    "    print(\"‚úÖ La carpeta ya tiene contenidos. Se omite la descarga.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9J9Y_yWYlE3"
   },
   "source": [
    "## üìÑ Extracci√≥n y Visualizaci√≥n de Contenido de Archivos PDF\n",
    "\n",
    "Este bloque realiza la lectura, procesamiento y previsualizaci√≥n del contenido de archivos PDF utilizando PyMuPDF (`fitz`):\n",
    "\n",
    "* **üì• `extract_text_from_pdf(file_path)`**  \n",
    "  Funci√≥n que **abre un archivo PDF y concatena el texto de todas sus p√°ginas** en un solo string, utilizando `fitz` para extraer el texto p√°gina por p√°gina.\n",
    "\n",
    "* **üìÇ Procesamiento de archivos PDF**  \n",
    "  Recorre todos los archivos dentro de la carpeta `/content/pdf`, aplica la funci√≥n anterior y guarda los resultados en un diccionario `pdf_texts` con la estructura `{nombre_archivo: texto_extra√≠do}`.\n",
    "\n",
    "* **üëÄ Previsualizaci√≥n de contenido**  \n",
    "  Por cada archivo procesado, **muestra los primeros 100 caracteres del contenido extra√≠do**, lo cual permite verificar r√°pidamente si la extracci√≥n fue exitosa y si el contenido es legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX3Ea3jlghLf",
    "outputId": "87006071-d947-4ce1-86a7-8c1a3113e4b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[Abre-tu-mente-modo-positivo-salud-mental.pdf]:\n",
      "\n",
      "1\n",
      "GU√çA PARA\n",
      "DOCENTES Y FAMILIAS\n",
      "PROMOCI√ìN DE SALUD\n",
      "MENTAL EN J√ìVENES\n",
      "PROMOCI√ìN DE SALUD MENTAL EN J√ì\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[Guiasautoayudadepresionansiedad.pdf]:\n",
      "\n",
      "PARA LA DEPRESI√ìN Y LOS TRASTORNOS DE ANSIEDAD\n",
      "PARA LA DEPRESI√ìN Y LOS TRASTORNOS DE ANSIEDAD\n",
      "Servic\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[empatia.pdf]:\n",
      "\n",
      "EMPAT√çA\n",
      "EL ARTE DE COMPRENDER EMOCIONES\n",
      "EMPAT√çA\n",
      "EL ARTE DE COMPRENDER EMOCIONES\n",
      "3\n",
      " Mahatma G a n d h\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[depresion.pdf]:\n",
      "\n",
      "Depresi√≥n \n",
      " \n",
      "¬øQu√© es la depresi√≥n?\n",
      "Todas las personas se sienten tristes o deca√≠das de vez en cuando\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[9789243548203_spa.pdf]:\n",
      "\n",
      "Primera ayuda psicol√≥gica:  Gu√≠a para trabajadores de \n",
      "campo\n",
      "Catalogaci√≥n por la Biblioteca de la OM\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[empatia_comunicacion.pdf]:\n",
      "\n",
      "1\n",
      "Empat√≠a en la comunicaci√≥n \n",
      "La empat√≠a en la comunicaci√≥n es fundamental para lograr una conexi√≥n \n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[Guia de Primeros Auxilios PsicoloÃÅgicos_Integra.pdf]:\n",
      "\n",
      "Gu√≠a de Primeros Auxilios \n",
      "Psicol√≥gicos (PAP) a personas en \n",
      "situaci√≥n de movilidad humana\n",
      "Gu√≠a de P\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf]:\n",
      "\n",
      "Lo mejor de tu vida eres t√∫\n",
      "Conf√≠a en la fuerza de tus emociones\n",
      "M.¬™ Jes√∫s √Ålava Reyes\n",
      "√çndice\n",
      "Agrade\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[AtencionPrimAmb1988_spa.pdf]:\n",
      "\n",
      "Organizaci√≥n Panamericana de la Salud \n",
      "#k' Organizaci√≥n Mundial de la Salud \n",
      "Divisi√≥n de Salud y Amb\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para extraer y concatenar el texto de todas las p√°ginas de un archivo PDF usando PyMuPDF (fitz)\n",
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Procesar todos los archivos PDF subidos\n",
    "pdf_texts = {}\n",
    "for filename in os.listdir(folder_path):\n",
    "      file_path = os.path.join(folder_path, filename)\n",
    "      text = extract_text_from_pdf(file_path)\n",
    "      pdf_texts[filename] = text\n",
    "\n",
    "# Mostrar los primeros 1000 caracteres de un archivo\n",
    "for name, content in pdf_texts.items():\n",
    "    print(f\">>> Desplegando previzualizaci√≥n del contenido del archivo üìö[{name}]:\\n\")\n",
    "    print(content[:100])\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVO3U5JxBpDi"
   },
   "source": [
    "## üß† Carga de Modelo de Embeddings Multiling√ºe\n",
    "\n",
    "üì¶ A continuaci√≥n se carga un modelo preentrenado de la librer√≠a `sentence-transformers`, espec√≠ficamente el modelo **`paraphrase-multilingual-MiniLM-L12-v2`**, el cual genera embeddings (representaciones vectoriales) de frases o textos.\n",
    "\n",
    "### ‚úÖ Razones para usar este modelo:\n",
    "* üåç **Multiling√ºe:** Soporta m√°s de 50 idiomas, ideal para trabajar con datos en distintos idiomas sin necesidad de traducir.\n",
    "* ‚ö° **Ligero y r√°pido:** Basado en la arquitectura MiniLM, lo que permite un buen equilibrio entre rendimiento y velocidad, incluso sin GPU.\n",
    "* üîç **Precisi√≥n en similitud sem√°ntica:** Entrenado para tareas como detecci√≥n de par√°frasis y b√∫squeda sem√°ntica, lo que lo hace muy √∫til para clustering, recuperaci√≥n de texto y comparaci√≥n de oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461,
     "referenced_widgets": [
      "7c9ce1e9a4f2495187c909359c74855e",
      "a9d49b1fb1014471bfd1e9adaa3d5e8b",
      "cac7d5cb2d45430788f534c80fa8dc25",
      "4ffa44d803784d809b59ef02d987a66b",
      "dda8f49f5b3a47e39743349b73a673d8",
      "e796fba887914264a6ed61d49c26d687",
      "0672b3407d204a13bd43addec952a105",
      "b4416b2c3b4f4bbaadc98575cb305715",
      "457115a19ac24d18afdf28c01bfe0586",
      "a745500903374c31b5917210b9073622",
      "ecf5a12e058142a6908449ac21156802",
      "8613b71310d94666b0e2659519490ee1",
      "15e04248416c4bd6b6f074c1a7822d80",
      "75655ea10667440f8a7b3a31722f51d8",
      "5c22e2daff2b4bbd855dd2e5807df77b",
      "cc411b32a04742f09d49f97620df5429",
      "a4ae3d4042fb4b11bfeb578de3ae78d2",
      "051a75c65c3a445ba5e119be26ecfcb8",
      "903a57c9a95340e4b594e80cf9c9929d",
      "eb0bd1db4bb14e78888009d04b6fd245",
      "a79539d57ce64cf9b27ad1cafcbe890a",
      "3f166fd1c364423eb551f0a3fab0a5e7",
      "838bb366b06f4955af6bceed730e5934",
      "c4a27448c4ca4e0092809d0d798dcd56",
      "6595594f21d3417bb6db60e32f66588e",
      "3d2ae8e25e164fd08558dcebddce2a01",
      "6b7d30cb0ddf48b2886874e1bfb61ed7",
      "acc00e664c0747f0bff843b339f531f0",
      "abcf0b1f4f814e4f99727f218bcd13b0",
      "2a008e1525c74dbda4e43c41abfda10c",
      "32421530c9a049d2abd791602f632257",
      "052ae2cdc0cf447489d4c0a8e9e1e778",
      "c1d0cdb4ee204b33a567268beac3778d",
      "d1a023f5e8f148fdb3c2859d73ef269f",
      "43747f6daadd44fcafc7e6a331f1fd2d",
      "64a4f0f56e4544789d7e39d99be1fee5",
      "53ebc92a8af84d64a66da1e3e65fab41",
      "42ce9aa560f548979f86c0b2c9aad010",
      "2fb1361632154c2baa96a905a1cd2b54",
      "5877343193a44d9b824d847bfc4076c7",
      "ddc5f06d5c7e4d36b9730f8cd044c64d",
      "31e45cc69ad34fbd8a63b27f9e362fb6",
      "f201f69bf14d4550af541f775e89974c",
      "2f6943bdafb4400cbb8c3ca4fdf0393b",
      "3e0c8d576ba04d6f81adce45ff35589f",
      "12d486f9a4f744058a11920838d2b2ca",
      "b7203066b1ec4c44a6daed409628e1be",
      "53a1ff85fa564b1db5b251c5802225f9",
      "d7b44fe51f9445719b2ce04eff0911c4",
      "01b2011d18bb4848bfb9c5c739fa4828",
      "c2816841bd834bad83e313d5f61c3287",
      "2deec3da72714f8aaf42f006c59fb104",
      "51fb25ada12440a28f865ba1d505b087",
      "201dfc3810d545d088fab4706419385f",
      "d43d6bdbf42b4f3a907720736818192e",
      "5211f3afb8924040b094a8c252c8081f",
      "75c5de19001a464aabac5c8de2a69be5",
      "e28ebaa0a9f443e6ae994c908593190f",
      "33c3ee816ac2444e95407ea47c9368af",
      "4eca25a128004b748ada54247936cc51",
      "8081193d29b04581a5967d02b7a85d4f",
      "c055588e63cd49a3a3ba0253bc81e405",
      "315206a8451f4ac69f3af81d21b0336b",
      "c69db73e1c7b479a9ee1251f9af995c2",
      "2286bd99b69d488e89f2e1f4415d92cf",
      "d978aba2a6294ea4812bac2b143edade",
      "08296094ae224eac8216ba0da47cee23",
      "79120e334fb94b74ac04181ac38ee8a1",
      "1512fb4b61b54712b6015fb3e792db14",
      "189ab14f67084106aa18a07d6981ab6b",
      "ec8cad76bc5244b792b57223fe5e1deb",
      "adc2e15b430348b9a64e50be38d40847",
      "9ca3244c06f34003a5802a59be26d9ab",
      "cf0dcf94b7734a1d8dad9e8897576d1e",
      "b9159c1d4da94236b2d25f82d2b5f48a",
      "b5003ac32c594481b1b37d2d5c671167",
      "c54bfe4291744222b22f74392fa12bd8",
      "2f35e0d213c242dfa68739779ada423a",
      "bf0383a3cee64da4a4fd8fd3f2eaa176",
      "ca446145297b462e99362ea36b3385c2",
      "f1e333fd55534f0e8fbf093556eb3055",
      "4d95bf0a3fa7498cb579211a02e427ee",
      "e61f7b4c507b42c884a6709b49762f6e",
      "efaf42c38bd94eabb2b39563f32af046",
      "609e85447ca64808b27af68bf527ca82",
      "07755b9002b54e7fa966e361f4577529",
      "f200a8d06e7e4303ae8b0c70730984a9",
      "d58dd8b15c194791bd21fce608224f44",
      "0b2f266ba1434e3995a5ab7c21f567e2",
      "738b941976c649948caddc31d9b36c29",
      "4dcedb5cc00a4ffe881bd8c9b0585fdd",
      "b546d63ca3e84977bd2a0938fcc57249",
      "e0b525caef884c6bac3b1bef214c5109",
      "b0061e65f26b4238b02280bb86b459c2",
      "46b294dd66134f86a1bd4eb56988d7b5",
      "b4b894454c12427e95e6fc9857affa7b",
      "e7b7c2d1477e40b8ac529aaa415dd72d",
      "d16a56a3c9ea477ebfd857814b4763ce",
      "5e8c038f00ac4e7a8fb1ac061740f4f4",
      "fd2e206b268e422fa7b54de5433dc9b8",
      "81a0b7e47b2442a2b77d621c8eaa37cf",
      "4dedf66737694eb699410f871fe2e784",
      "ae2e636504f444f58459797e2edb89bd",
      "a0130d6b4d5646a9bc8a39915604b09c",
      "0454452f56654bc5aa02bd4d9607edab",
      "b1fcb06629624750a748e7237a00d324",
      "69116cd9ba054a3fb7942a74840a6a69",
      "2cd58200ce0e4ba4adca89069421463e",
      "b4719b9607284daabd9ae49f356de230",
      "3351b8b79b8b41fe8c3b687690fd9ca2"
     ]
    },
    "id": "Bfs5Zxc9j7Uf",
    "outputId": "f3f455b5-8359-4ca5-90e0-70c0f107144a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9ce1e9a4f2495187c909359c74855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8613b71310d94666b0e2659519490ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838bb366b06f4955af6bceed730e5934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a023f5e8f148fdb3c2859d73ef269f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0c8d576ba04d6f81adce45ff35589f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5211f3afb8924040b094a8c252c8081f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08296094ae224eac8216ba0da47cee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35e0d213c242dfa68739779ada423a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2f266ba1434e3995a5ab7c21f567e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2e206b268e422fa7b54de5433dc9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargando modelo preentrenado\n",
    "model_sentence = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqHZsyC_ZmNK"
   },
   "source": [
    "## ‚úÇÔ∏è Divisi√≥n Sem√°ntica de Texto por Oraciones\n",
    "\n",
    "Esta funci√≥n divide un texto en fragmentos **respetando los l√≠mites de tokens y las fronteras sem√°nticas de las oraciones**, usando `sent_tokenize()` de NLTK.\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "* üß† Divide el texto en oraciones individuales.\n",
    "* üì¶ Agrupa las oraciones en bloques cuya **longitud no supere `max_tokens` (por defecto 25 palabras)**.\n",
    "* üîÅ Aplica **solapamiento configurable (`overlap`)** entre bloques, preservando coherencia contextual entre fragmentos.\n",
    "* ‚úÖ Devuelve una lista de bloques listos para an√°lisis sem√°ntico, embeddings o respuestas de chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QRStndlYL_hD"
   },
   "outputs": [],
   "source": [
    "# CHUNKING SEMANTICO CON NLTK\n",
    "# Funci√≥n para dividir el texto en fragmentos (oraciones)\n",
    "def split_text_semantic(text, max_tokens=25, overlap=1):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "    for sentence in sentences:\n",
    "        token_count = len(sentence.split())\n",
    "        if current_len + token_count > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = current_chunk[-overlap:] if overlap > 0 else []\n",
    "            current_len = sum(len(s.split()) for s in current_chunk)\n",
    "        current_chunk.append(sentence)\n",
    "        current_len += token_count\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Funci√≥n para dividir el texto en fragmentos (chunks) - NOT USED\n",
    "def split_text(text, chunk_size=500, overlap=50): ##chunk_size=5000, overlap=50)\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsckZ09AxzBA"
   },
   "source": [
    "## üß† Fragmentaci√≥n, Vectorizaci√≥n y Creaci√≥n del √çndice Sem√°ntico\n",
    "\n",
    "* **Fragmenta textos PDF, genera sus embeddings y construye un √≠ndice FAISS para habilitar b√∫squedas sem√°nticas en un chatbot.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üß© **Fragmentaci√≥n sem√°ntica de documentos**  \n",
    "  Recorre los textos extra√≠dos de los PDFs y los divide en fragmentos utilizando `split_text_semantic`, que respeta los l√≠mites de oraci√≥n y evita cortes arbitrarios. Luego, cada fragmento se guarda junto con su metadato correspondiente (nombre del archivo y contenido del fragmento).\n",
    "\n",
    "* üß¨ **Generaci√≥n y normalizaci√≥n de embeddings**  \n",
    "  Los fragmentos generados se convierten en vectores sem√°nticos (embeddings) mediante un modelo de `sentence-transformers`. A continuaci√≥n, se normalizan para que todos tengan norma unitaria, lo cual es necesario para aplicar similitud coseno correctamente.\n",
    "\n",
    "* üß≠ **Construcci√≥n del √≠ndice FAISS**  \n",
    "  Se crea un √≠ndice FAISS utilizando `IndexFlatIP`, dise√±ado para trabajar con similitud coseno entre vectores normalizados. Luego se agregan todos los embeddings al √≠ndice para habilitar b√∫squedas r√°pidas y precisas.\n",
    "\n",
    "Este flujo pemrite que el chatbot pueda realizar b√∫squedas sem√°nticas inteligentes y responder preguntas con base en el contenido de m√∫ltiples documentos PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c0d3a93420894447bd5e5a8629eda95a",
      "385a9862fa624249b8df35689e5cc6f4",
      "e8b83a19f186403d8db50909aafd9e2e",
      "dd28d82ecb0b41488b29df6074b6c395",
      "b94d88910bc04b83b1fef97c7ce5d96a",
      "8e8da74faef44d13998b070d2aec09f1",
      "3f8ff8675c434d849e9ff9cc277811c5",
      "466a1f0c3f544da2ab2b9d0f9672e28e",
      "b0464e3b9f6d4b7ea1eb96ed0b5e5c0a",
      "d033cc15fa7b4f84bf331594b6f37d20",
      "def59040f8e347ef836d7eabcfb5bd45"
     ]
    },
    "id": "CikjqV0MiO0L",
    "outputId": "48443f5b-20ef-4f20-9f30-850c3302533b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d3a93420894447bd5e5a8629eda95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recorrer todos los archivos PDF, divide su contenido en fragmentos,\n",
    "# y guarda tanto los textos como los metadatos (nombre del archivo y texto del fragmento)\n",
    "all_chunks = []\n",
    "metadata = []\n",
    "for filename, text in pdf_texts.items():\n",
    "    #chunks = split_text(text)\n",
    "    chunks = split_text_semantic(text)\n",
    "    all_chunks.extend(chunks)\n",
    "    metadata.extend([{\"source\": filename, \"text\": chunk} for chunk in chunks])\n",
    "\n",
    "# Crear embeddings\n",
    "embeddings = model_sentence.encode(all_chunks, show_progress_bar=True)\n",
    "embeddings = normalize(embeddings, axis=1)  # normalizar para usar cosine similarity (IndexFlatIP)\n",
    "\n",
    "# Crear √≠ndice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "#index = faiss.IndexFlatL2(dimension)\n",
    "index = faiss.IndexFlatIP(dimension) # Se usa IndexFlatIP oara cosine similatiry\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLr68Bo-yI9T"
   },
   "source": [
    "## üíæ Guardado del √çndice y Metadatos\n",
    "\n",
    "* **Guarda el √≠ndice FAISS y los metadatos para reutilizarlos sin reprocesar los documentos.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üß≠ **Guardar el √≠ndice FAISS**  \n",
    "  Se almacena el √≠ndice generado en un archivo `.faiss`, lo que permite reutilizarlo en futuras sesiones sin tener que volver a generar todos los embeddings y reconstruir el √≠ndice desde cero.\n",
    "\n",
    "* üóÇÔ∏è **Guardar los metadatos**  \n",
    "  Los metadatos (informaci√≥n del fragmento y su documento de origen) se guardan en un archivo `.pkl` usando `pickle`. Esto es esencial para que, al recuperar un fragmento desde el √≠ndice, el chatbot pueda identificar de qu√© archivo proviene y mostrarlo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t4fkfNKljEhv"
   },
   "outputs": [],
   "source": [
    "# Guardar FAISS index\n",
    "faiss.write_index(index, \"chatbot_index.faiss\")\n",
    "\n",
    "# Guardar los metadatos\n",
    "with open(\"chatbot_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF87r29u5glB"
   },
   "source": [
    "# **Sistema RAG + LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eLAz39byWFB"
   },
   "source": [
    "Un sistema **RAG** (Retrieval-Augmented Generation) es una arquitectura de inteligencia artificial que combina recuperaci√≥n de informaci√≥n con generaci√≥n de texto, con el objetivo de mejorar la precisi√≥n, relevancia y actualidad de las respuestas generadas por modelos de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqrMSMxG42ZJ"
   },
   "source": [
    "## üß† Modelos LLM y de Embeddings\n",
    "\n",
    "* **Carga un modelo de lenguaje para generaci√≥n de respuestas y un modelo de embeddings para comprensi√≥n sem√°ntica.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üí¨ **Modelo generador de respuestas (LLM)**  \n",
    "  Se carga el modelo `google/flan-t5-base`, un modelo de tipo encoder-decoder optimizado para tareas text-to-text.  \n",
    "  A trav√©s de `AutoTokenizer` y `AutoModelForSeq2SeqLM` de `transformers`, se inicializa el modelo junto con su tokenizador, y se configura un `pipeline` de generaci√≥n de texto (`text2text-generation`).  \n",
    "  Este modelo permite al chatbot **redactar respuestas completas en lenguaje natural** a partir de consultas y contextos.\n",
    "\n",
    "* üß© **Modelo de embeddings sem√°nticos**  \n",
    "  Se carga el modelo `paraphrase-multilingual-MiniLM-L12-v2` de `sentence-transformers`, el cual convierte oraciones o fragmentos de texto en vectores num√©ricos.  \n",
    "  Estos vectores permiten comparar significados y buscar respuestas relevantes dentro del √≠ndice FAISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "15feb54fb977443c960db2fbb242a58c",
      "941d75c581d445f3b01eb0b9383c9d2e",
      "70798e92ebeb4f499bf39d25ecdf591b",
      "2179ad2a05c24f1abafde570b30b7dda",
      "bebeae10407d4a0fb90c4467823c2899",
      "6d738446bd5341a8a1953eb6ade7f92c",
      "af26174bb8fb40caafe651551ed7c31a",
      "3b7b10095f8c43ad896f0f11811364e7",
      "6e6e4ab233e9435c85300869d26cd191",
      "673ae4798fd6462c9efefac9b378635c",
      "eb768025d23d4a90ba4d3222220a708b",
      "a0b853b2ef97468dafca15248a7de073",
      "41d0f170938740748586d40858ad67f7",
      "a4fb393c334b45b28b7a223b04c1d7bd",
      "26c322d632f44543a96f6984a8269d4a",
      "50935fab91614b669d87d477965d3012",
      "f7266a76a186403ca377d0204feea8c4",
      "04ea2821efb24ccdae4d27d446b3544f",
      "d56537203a0a4fed9c57b806339a1e6d",
      "47d87502eca5489981b8e1becddd78d0",
      "1d19a283b2b74c1681466e197080d644",
      "0a13cd6866a64df290377dd909b34944",
      "9a6fb9a7896147589ad6183fafddbe46",
      "6c259bf55ea24c53b2672b097a56907e",
      "52610e9332bd47eb8bb327f3d124df3a",
      "04bda817df554ee29c56055374d0c6f9",
      "5e4acb54a89d4b5d82f8af42783c60e8",
      "1d582ace5a5c40f9aed7e9ea002154ab",
      "7d3465b63c114f389868dafabce7ff30",
      "168107171e7f438dbac6dbc2257d4abb",
      "7ba767f282a249fcbf718df0440046eb",
      "bd75af0ab3344105a94f960667406202",
      "af62bb781e9447c590f47330637da6fc",
      "8ff183aac518458e862b3ee0ec92ff62",
      "f92fa2d550de419b8aa9853f0b2dfc15",
      "0bd9ba20d98740a595b17f6aeea7be2b",
      "2ff60926f356408d88c4936c5f2c4767",
      "f173e3e64c5749df84619781eb93c7af",
      "38efb1da128544e8aebb4126bf59ce4c",
      "91ce6ae88e5143739cddf77e982b8023",
      "86b71d53b235422fa2957ff89480b1da",
      "a0289d8adb9d470d8961912910494604",
      "0738f36ae5354c2caaf9e63558f1d9c7",
      "1bd875334a8d4092906b88d3e61bc263",
      "375e118003f547588b553ec061996228",
      "27352229811c4485ae6502d256ffdb46",
      "ab1912231f6d4ef5a1d6c8b9d8c390e3",
      "6e98ef0888d340dbb75e785fc9ea569d",
      "1907de7aa5fe48a0a662d287246408ea",
      "d842910f82db4d9d8f977d10eb9077d1",
      "78879fdc85e84bb59308634fd973ffda",
      "0bbf7134419d44869bdcecf1c33a1cee",
      "db37f4e22fc14847b800ea759edf7a1a",
      "0511580863e346d3b863b3eee2945629",
      "4607e6b42cbf4dc09002ea4708f4f8f6",
      "9eb6fbf47db842cea18ce114e7b24368",
      "cab5ad1086a940aba972f66d8c3405c8",
      "2e227431f7ae405bb045ca6f647d127f",
      "2bd754077ced462aa5375fa5310e1b6a",
      "e140d21ffe954fd88392bcc9cabb59f2",
      "2f0eeed61acc4e65bf811e226431ee78",
      "8b9a242fa2974a3ebe7fe039d99258ed",
      "1fc8b1b4c70d4074902ba51a80e65d52",
      "550ca31186db4607ab24a1ec06c6aee2",
      "77f85a4f9f084d169f9a2bf496716141",
      "57b266283e4d49c8b0c02641dfc9a8fc",
      "dc794639547c42a0bc04d6d36f04dc3f",
      "fe4a6498eee3447b91e0f2a87dcf43c5",
      "cda7f2a0c5c943e5b0f687e8a5947811",
      "7cc43cba8a5242a4a447b06b85cbe0f5",
      "6bdec17ea8134b3aaa6d21f03d1b90c9",
      "6eff818b1bcf4296b31cda9e52b4bbbf",
      "148127a498a84b469341f00e5ee7a946",
      "3a3792a8e6ae443f94da02731a38e98d",
      "3d604ee387d24115bdcfc3fd89935985",
      "b014f1e10c9d4232a71aa908419e977c",
      "586863b2f6904909aec90a968bd47b35"
     ]
    },
    "id": "SsTf0kyInanM",
    "outputId": "8bb72768-b595-46d9-9e4c-4a1b4a50624f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15feb54fb977443c960db2fbb242a58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b853b2ef97468dafca15248a7de073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6fb9a7896147589ad6183fafddbe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff183aac518458e862b3ee0ec92ff62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375e118003f547588b553ec061996228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb6fbf47db842cea18ce114e7b24368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc794639547c42a0bc04d6d36f04dc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# LLM para generar respuestas\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Modelo para embeddings (vectorizaci√≥n)\n",
    "embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEm3RbcU5Je0"
   },
   "source": [
    "## üß† B√∫squeda Sem√°ntica y Generaci√≥n de Respuestas\n",
    "\n",
    "* **Estas funciones permiten buscar fragmentos relevantes mediante similitud sem√°ntica y generar respuestas con un modelo LLM.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üîé **`search_similar_chunks( )`**  \n",
    "  Genera un embedding para la consulta del usuario y lo compara contra el √≠ndice FAISS para encontrar los fragmentos m√°s relevantes.  \n",
    "  Si no se encuentra ning√∫n resultado con una similitud suficiente (basada en el `threshold`), retorna `None`.  \n",
    "  Si hay coincidencias, devuelve los textos correspondientes desde los metadatos.\n",
    "\n",
    "* üß© **`build_prompt( )`**  \n",
    "  Construye un mensaje (prompt) combinando los fragmentos de contexto recuperados con la pregunta del usuario.  \n",
    "  Este prompt es lo que se le entrega al modelo generador para que forme una respuesta informada y contextualizada.\n",
    "\n",
    "* üí¨ **`generate_answer( )`**  \n",
    "  Orquesta el flujo completo: busca los fragmentos m√°s parecidos a la consulta, genera el prompt y produce una respuesta con el modelo `flan-t5-base`.  \n",
    "  Si no se encuentran fragmentos relevantes, devuelve un mensaje de disculpa.\n",
    "\n",
    "* üíæ **Carga del √≠ndice y metadatos**  \n",
    "  Se cargan el √≠ndice FAISS (`chatbot_index.faiss`) y los metadatos (`chatbot_metadata.pkl`) previamente guardados, para que el sistema est√© listo para responder sin tener que reentrenar o reprocesar documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WlVqMthHneso"
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, context_chunks):\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = (\n",
    "        f\"Con este contexto:\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"Responde brevemente:\\n\"\n",
    "        f\"{query}\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def search_similar_chunks(query, top_k=3, threshold=0.3):\n",
    "    query_embedding = embedder.encode([query])\n",
    "    query_embedding = normalize(query_embedding, axis=1) #Normalizar los embeddings\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    if max(distances[0] < threshold):\n",
    "      return None\n",
    "\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        results.append(metadata[i]['text'])\n",
    "    return results\n",
    "\n",
    "def generate_answer(query, top_k=3):\n",
    "    chunks = search_similar_chunks(query, top_k=top_k)\n",
    "    if chunks is None:\n",
    "      return \"Lo siento, no encontr√© informaci√≥n suficiente para responder a eso.\"\n",
    "    prompt = build_prompt(query, chunks)\n",
    "\n",
    "    output = generator(prompt, max_new_tokens=256, do_sample=False)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "# Cargar √≠ndice\n",
    "index = faiss.read_index(\"chatbot_index.faiss\")\n",
    "\n",
    "# Cargar metadatos\n",
    "with open(\"chatbot_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOfeqsQb5ttD"
   },
   "source": [
    "# **El chatbot, incluyendo ejemplos de prueba.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiyJ8qcM5ltH"
   },
   "source": [
    "## ü§ñ Prueba de Consultas al Chatbot\n",
    "\n",
    "* **Eval√∫a una lista de preguntas simuladas y muestra las respuestas generadas.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üßæ **Lista de preguntas (`queries`)**  \n",
    "  Contiene ejemplos representativos de preguntas que un usuario podr√≠a hacerle al chatbot, relacionadas con ansiedad, depresi√≥n y emociones humanas.\n",
    "\n",
    "* üîÑ **Bucle de interacci√≥n con el chatbot**  \n",
    "  Para cada pregunta:\n",
    "  - Se imprime la consulta.\n",
    "  - Se llama a `generate_answer()` para obtener una respuesta contextual.\n",
    "  - La respuesta se imprime.\n",
    "\n",
    "Este bloque permite probar y validar c√≥mo responde el sistema a distintas consultas, ideal para demostraciones, testing o debugging del chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t3eNHkfkGvx",
    "outputId": "fd754143-341a-4bad-e74b-a4600287d583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "C√≥mo superar la ansiedad?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "‚Ä¢ Controle su preocupaci√≥n. Escoja un lugar y una hora para preocuparse. ‚Ä¢ Los sntomas de ansiedad originales pueden volver. Considere otras formas de hacer frente a sus sntomas. For example, aprenda a relajarse. Cambiar los comportamientos relacionados con la ansiedad ‚Ä¢ Trate de reconocer cuando est√° evitando cosas. ‚Ä¢ Siempre que se puede tratar de hacer frente a estostemores, no todos a la vez pero siempre gradual. Responde briefly:\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Qu√© es ansiedad?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "Para la ansiedad Los sntomas de la ansiedad incluyen: agitaci√≥n, tensi√≥n, irritabilidad, palpitaciones, temblores, sudoraci√≥n, preocuparse en exceso, dormir mal, falta de concentraci√≥n, respiraci√≥n rapida, sensaci√≥n de ‚Äúpellizco en el est√≥mago‚Äù y tensi√≥n muscular\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Cuando es grave la ansiedad?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "‚Ä¢ Graves and desagradables. ‚Ä¢ Duran mucho tiempo. ‚Ä¢ Ocurren con demasiada frecuencia. S. Son los siguientes: ‚Ä¢ Trastorno de ansiedad generalizada. La ansiedad puede ser una sensaci√≥n general y constante de preocupaci√≥n. Para la ansiedad Los sntomas de la ansiedad incluyen: agitaci√≥n, tensi√≥n, irritabilidad, palpitaciones, temblores, sudoraci√≥n, preocuparse en exceso, dormir mal, falta de concentraci√≥n, respiraci√≥n rapida, sensaci√≥n de ‚Äúpellizco en el est√≥mago‚Äù y tensi√≥n muscular\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Cuales son los sintomas de la ansiedad\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "agitaci√≥n, tensi√≥n, irritabilidad, palpitaciones, temblores, sudoraci√≥n, preocuparse en exceso, dormir mal, falta de concentraci√≥n, respiraci√≥n r√°pida, sensaci√≥n de ‚Äúpellizco en el est√≥mago‚Äù y tensi√≥n muscular.\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Qu√© hacer si estoy triste?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "Me echo a llorar por cualquier cosa y todo me sienta mal. No digas ‚ÄúEstoy triste‚Äù si las palabras que mejor describiran tu estado emocional seran decepcionado, compungido, melanc√≥lico o herido. S√© concreto.\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Qu√© es una depresi√≥n?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "La depresi√≥n es una enfermedad, como lo es la diabetes o una lcera de est√≥mago\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "¬øC√∫ales son las causas de la depresi√≥n?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "Para lo general, se considera que existen ‚Äúfactores‚Äù biol√≥gicos, psicol√≥gicos y ambientales (aqu√©ls relacionados con el entorno social o la familia).\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Quieres ser mi amigo?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "Puedo encontrar a una amiga que me acompae y aprovechar para conversar.\n",
      "============================================================\n",
      ">> üë®üèª‚Äçüíª Pregunta realizada:\n",
      "Que es un iPhone?\n",
      "\n",
      "++ üíª Respuesta del chatbot:\n",
      "Lo siento, no encontr√© informaci√≥n suficiente para responder a eso.\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"C√≥mo superar la ansiedad?\",\n",
    "    \"Qu√© es ansiedad?\",\n",
    "    \"Cuando es grave la ansiedad?\",\n",
    "    \"Cuales son los sintomas de la ansiedad\",\n",
    "    \"Qu√© hacer si estoy triste?\",\n",
    "    \"Qu√© es una depresi√≥n?\",\n",
    "    \"¬øC√∫ales son las causas de la depresi√≥n?\",\n",
    "    \"Quieres ser mi amigo?\",\n",
    "    \"Que es un iPhone?\"\n",
    "           ]\n",
    "\n",
    "for query in queries:\n",
    "  print(f\"=\"*60)\n",
    "  print(f\">> üë®üèª‚Äçüíª Pregunta realizada:\\n{query}\\n\")\n",
    "  respuesta = generate_answer(query)\n",
    "  print(\"++ üíª Respuesta del chatbot:\")\n",
    "  print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBUXG3vr56ev"
   },
   "source": [
    "## üñºÔ∏è Despliegue de Interfaz Interactiva con Gradio\n",
    "\n",
    "* **Por √∫ltimo, se crea una interfaz web simple para interactuar con el chatbot directamente desde el navegador.**\n",
    "\n",
    "### ‚öôÔ∏è ¬øC√≥mo funciona?\n",
    "\n",
    "* üîå **`chat_interface(question)`**  \n",
    "  Define una funci√≥n que toma una pregunta como entrada, genera una respuesta utilizando `generate_answer()`, y la retorna. Esta ser√° la funci√≥n que conecta la interfaz con la l√≥gica del chatbot.\n",
    "\n",
    "* üß™ **`gr.Interface(...)`**  \n",
    "  Utiliza la librer√≠a `Gradio` para crear una interfaz gr√°fica m√≠nima:\n",
    "  - `inputs=\"text\"` permite al usuario ingresar una pregunta en una caja de texto.\n",
    "  - `outputs=\"text\"` muestra la respuesta generada.\n",
    "  - `launch(share=True)` despliega la interfaz y genera un enlace p√∫blico para compartirla f√°cilmente.\n",
    "\n",
    "  ### Captura de interfaz con Gradio:\n",
    "  <img src=\"https://drive.google.com/uc?id=1cyyi2xpzoqWzWiK4OQVcgSx9eUTEwXwx\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QVsp7TrQsvS"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "Lw1bxsYeQrMn",
    "outputId": "d2a28fd4-7869-4434-8472-45465a3f7d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://319af64969c77be213.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://319af64969c77be213.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def chat_interface(question):\n",
    "    answer = generate_answer(question)\n",
    "    return answer\n",
    "gr.Interface(fn=chat_interface, inputs=\"text\", outputs=\"text\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx-dZSFJz9cK"
   },
   "source": [
    "\n",
    "# **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w3usdaC0BCj"
   },
   "source": [
    "* #### **Conclusiones de la actividad chatbot LLM + RAG:**\n",
    "\n",
    "**Aprendizajes generales**\n",
    "- Como equipo, logramos implementar un enfoque de Retrieval-Augmented Generation que permiti√≥ combinar la potencia de los modelos generativos con la precisi√≥n del sistema de recuperaci√≥n documental mediante FAISS. Esto demostr√≥ ser √∫til para responder preguntas espec√≠ficas del dominio de salud mental, generando respuestas contextualizadas y coherentes.\n",
    "\n",
    "- Al utilizar corpus en espa√±ol y modelos preentrenados compatibles con el idioma, se busc√≥ la adecuaci√≥n ling√º√≠stica del chatbot para usuarios hispanohablantes. Este enfoque nos confirma la importancia de adaptar los modelos LLM a las necesidades culturales y ling√º√≠sticas de los usuarios.\n",
    "\n",
    "- El prototipo desarrollado tiene potencial para convertirse en una herramienta de apoyo accesible para personas en b√∫squeda de informaci√≥n confiable y actualizada relacionada con salud mental.\n",
    "\n",
    "- Se comprendi√≥ la arquitectura RAG como una soluci√≥n que combina lo mejor del acceso a informaci√≥n (retrieval) con la generaci√≥n fluida de lenguaje natural (LLM).\n",
    "\n",
    "- Se identific√≥ que los modelos LLM por s√≠ solos pueden llegar a tener l√≠mites si no est√°n conectados a una base de conocimiento actualizada o contextual.\n",
    "\n",
    "- El enfoque RAG permiti√≥ ofrecer respuestas m√°s precisas, relevantes y trazables, especialmente √∫til en temas delicados como salud mental.\n",
    "\n",
    "\n",
    "**T√©cnicas y Herramientas Implementadas**\n",
    "\n",
    "- Se utilizaron embeddings sem√°nticos para representar texto y permitir b√∫squedas por similitud en lugar de coincidencia exacta de palabras clave.\n",
    "\n",
    "- Se trabaj√≥ con herramientas como FAISS para construir √≠ndices de recuperaci√≥n eficientes.\n",
    "\n",
    "- Se aplic√≥ un umbral de similitud para filtrar respuestas no relacionadas, mejorando la precisi√≥n del chatbot.\n",
    "\n",
    "- Se integr√≥ el sistema en una interfaz interactiva mediante Gradio, facilitando la interacci√≥n con el usuario final.\n",
    "\n",
    "- Se reafirm√≥ la importancia del preprocesamiento del texto, incluyendo limpieza, normalizaci√≥n y tokenizaci√≥n.\n",
    "\n",
    "- Se emplearon modelos preentrenados de HuggingFace Transformers para tareas de generaci√≥n de texto, en busca de coherencia y naturalidad.\n",
    "\n",
    "- Se comprob√≥ que los LLM pueden ampliar, matizar o contextualizar mejor la informaci√≥n cuando se utilizan junto con RAG.\n",
    "\n",
    "- Se logr√≥ generar respuestas basadas en fuentes espec√≠ficas.\n",
    "\n",
    "- Se apreciaron los beneficos de que es un enfoque modular y escalable, permitiendo incorporar nuevos documentos sin necesidad de reentrenar el modelo.\n",
    "\n",
    "**Retos y Reflexiones**\n",
    "\n",
    "- Se observan oportunidades en las respuestas, ya que hay errores en cuanto a formato, mezcla de idiomas e incluso omisi√≥n de caracteres. Esto pudiera mejorarse ya sea agregando instrucciones al prompt, hacer un proceso de limpieza m√°s extensivo o aplicar filtros de idioma. Incluso usar modelos m√°s pesados y potentes, con modelos de paga.\n",
    "\n",
    "- Se identific√≥ que definir un umbral de similitud adecuado es clave para evitar respuestas irrelevantes.\n",
    "\n",
    "- Se observ√≥ que la curaci√≥n del corpus (selecci√≥n y fragmentaci√≥n del contenido) tiene un impacto directo en la calidad del chatbot.\n",
    "\n",
    "- Se concluy√≥ que este enfoque puede adaptarse a otros dominios como educaci√≥n, derecho, atenci√≥n m√©dica o servicio al cliente.\n",
    "\n",
    "- Se reconoci√≥ que la estructura RAG es multiling√ºe y adaptable, facilitando su implementaci√≥n en diversos contextos.\n",
    "\n",
    "- Se evidenci√≥ el potencial para escalar esta tecnolog√≠a hacia sistemas m√°s complejos como tutores virtuales, asistentes personales o motores de b√∫squeda especializados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLCGSshm7k9j"
   },
   "source": [
    "# Referencias\n",
    "\n",
    "### Referencias\n",
    "\n",
    "* Amazon Web Services (AWS). (2025). *¬øQu√© es la generaci√≥n aumentada por recuperaci√≥n (RAG)?*. Recuperado de https://aws.amazon.com/es/what-is/retrieval-augmented-generation/\n",
    "* DeepLearning.AI. (2024). *LangChain for LLM Application Development*. Recuperado de https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\n",
    "* Google Cloud. (2025). *Uso de RAG: casos de uso de generaci√≥n aumentada por recuperaci√≥n*. Recuperado de https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=es\n",
    "* Gradio. (2025). *Quickstart Guide for Gradio: construir y compartir demos de ML en Python*. Recuperado de https://www.gradio.app/guides/quickstart\n",
    "* Hohls, J. K., K√∂nig, H.-H., Quirke, E., & Hajek, A. (2021). Anxiety, Depression and Quality of Life--A Systematic Review of Evidence from Longitudinal Observational Studies. *International Journal of Environmental Research and Public Health*, *18*(22), 12022. https://doi.org/10.3390/ijerph182212022\n",
    "* Hua, Y., Na, H., Li, Z., & et al. (2025). A scoping review of large language models for generative tasks in mental health care. *npj Digital Medicine*, *8*, 230. https://doi.org/10.1038/s41746-025-01611-4\n",
    "* O'Reilly Media. (2025). *Retrieval‚ÄëAugmented Generation (RAG) and LLMs*. Recuperado de https://www.oreilly.com/live-events/retrieval-augmented-generation-rag-and-llms/0790145078618/\n",
    "* Palomares, I. (2024). *Boost LLM Accuracy with Retrieval Augmented Generation (RAG) & Reranking*. Recuperado de https://www.datacamp.com/es/tutorial/boost-llm-accuracy-retrieval-augmented-generation-rag-reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtB5Q3m41YQ0"
   },
   "source": [
    "# **Fin de la actividad chatbot: LLM + RAG**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
