{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hVND8xY2OKY"
   },
   "source": [
    "# **Procesamiento de Lenguaje Natural**\n",
    "\n",
    "## MaestrÃ­a en Inteligencia Artificial Aplicada\n",
    "#### TecnolÃ³gico de Monterrey\n",
    "#### Prof Luis Eduardo FalcÃ³n Morales\n",
    "\n",
    "### **Adtividad en Equipos: sistema LLM + RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aimHVFOv23lm"
   },
   "source": [
    "* **Nombres y matrÃ­culas:**\n",
    "\n",
    "* ğŸ§‘â€ğŸ’» Ovidio Alejandro HernÃ¡ndez Ruano (A01796714)\n",
    "* ğŸ§‘â€ğŸ’» JosÃ© Manuel Toral Cruz (A01122243)\n",
    "* ğŸ§‘â€ğŸ’» Oscar Enrique GarcÃ­a GarcÃ­a (A01016093)\n",
    "* ğŸ§‘â€ğŸ’» Luis Gerardo Sanchez Salazar (A01232963)\n",
    "\n",
    "* **NÃºmero de Equipo:**\n",
    "* Equipo #20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jimvsiVgjMg"
   },
   "source": [
    "* ##### **El formato de este cuaderno de Jupyter es libre, pero debe incuir al menos las siguientes secciones:**\n",
    "\n",
    "  * ##### **IntroducciÃ³n de la problemÃ¡tica a resolver.**\n",
    "  * ##### **Sistema RAG + LLM**\n",
    "  * ##### **El chatbot, incluyendo ejemplos de prueba.**\n",
    "  * ##### **Conclusiones**\n",
    "\n",
    "* ##### **Pueden importar los paquetes o librerÃ­as que requieran.**\n",
    "\n",
    "* ##### **Pueden incluir las celdas y lÃ­neas de cÃ³digo que deseen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2akzn895aF_"
   },
   "source": [
    "# **IntroducciÃ³n de la problemÃ¡tica a resolver.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq3bI2BBBm97"
   },
   "source": [
    "## ğŸ’¡ Ansiedad y depresiÃ³n: Falta de acceso inmediato, confiable y seguro a informaciÃ³n\n",
    "\n",
    "**La ansiedad y la depresiÃ³n** son dos de los transtornos de salud mental mÃ¡s comunes a nivel mundial, afectando a millones de personas de todas las edades. (Hohls et al., 2021) A pesar de su prevalencia, muchas personas no cuentan con acceso oportuno a informaciÃ³n clara, comprensible y basada en evidencia que les permita entender sus sÃ­ntomas, buscar ayuda o simplemente sentirse acompaÃ±adas en su proceso.\n",
    "\n",
    "Factores como la estigma social, la desinformaciÃ³n, las barreras econÃ³micas, la escasez de profesionales en salud mental y largos tiempos de espera para recibir atenciÃ³n dificultan quee quienes sufren de estos trastornos obtengan orientaciÃ³n adecuada. AdemÃ¡s, en entornos digitales sobrecargados de contenido, es frecuente encontrar informaciÃ³n errÃ³nea, poco Ãºtil o incluso perjudicial (Hua et al., 2025).\n",
    "\n",
    "En este contexto, se propone el desarrollo de un **chatbot** especializado en ansiedad y depresiÃ³n, que brinde respuestas confiables, empÃ¡ticas y accesibles. Este asistente digital tiene como objetivo reducir la brecha de informaciÃ³n, orientar a las personas hacia recursos apropiados y contribuir al bienestar emocional desde un enfoque preventivo y educativo.\n",
    "\n",
    "Para el desarrollo del chatbot, se usarÃ¡ Retrieval-Augmented Generation (**RAG**) en combinaciÃ³n de modelos de lenguaje de gran escala (**LLM**), generando asÃ­ una soluciÃ³n efectiva, principalmente por las siguientes razones:\n",
    "\n",
    "* âœ… **ActualizaciÃ³n y precisiÃ³n sobre el contenido:** RAG permite que el modelo no genere respuestas aleatorias basadas en su entrenamiento previo, sino que consulte una base documental curada como guÃ­as clÃ­nicas, material psicoeducativo validado, publicaciones cientÃ­ficas, o preguntas frecuentes verificadas, reduciendo el riesgo de respuestas incorrectas o no fundamentadas, lo cual es crucial al tratar temas sensibles como la salud mental.\n",
    "\n",
    "* âœ… **ActualizaciÃ³n dinÃ¡mica y adaptabilidad**: A diferencia de un LLM puro, que no puede aprender nueva informaciÃ³n tras su entrenamiento, un sistema RAG puede actualizar fÃ¡cilmente su corpus de conocimiento sin necesidad de reentrenamiento. AsÃ­, el chatbot puede mantenerse actualizado con las Ãºltimas recomendaciones clÃ­nicas, normativas locales o recursos disponibles (como lÃ­neas de ayuda o centros de atenciÃ³n comunitarios) o incluso, diagnÃ³sticos, conversaciones, o historiales clÃ­nicos del paciente para una experiencia mÃ¡s personalizada.\n",
    "\n",
    "* âœ… **Respuestas contextuales, empÃ¡ticas y comprensibles**: El LLM permite que las respuestas se generen en lenguaje natural, adaptadas al tono del usuario, con un estilo conversacional empÃ¡tico y accesible. Esto ayuda a que las personas se sientan comprendidas y no juzgadas, y que la informaciÃ³n se transmita con claridad y calidez (Palomares, 2024).\n",
    "\n",
    "* âœ… **Escalabilidad y disponibilidad**: Al ser una soluciÃ³n automatizada, el chatbot puede estar disponible 24/7, sin importar la zona horaria ni la demanda, lo que permite llegar a mÃ¡s personas en momentos de urgencia o duda. Esto lo convierte en una herramienta valiosa en comunidades con recursos limitados (AWS, 2025).\n",
    "\n",
    "* âœ… **Privacidad y anonimato**: Muchos usuarios prefieren explorar sus dudas sobre salud mental de forma anÃ³nima, sin tener que hablar cara a cara con un profesional desde el inicio. Un chatbot con estas caracterÃ­sticas ofrece un espacio seguro, privado y no intrusivo donde dar los primeros pasos hacia el autocuidado o la bÃºsqueda de ayuda (Hua et al., 2025).\n",
    "\n",
    "Combinar RAG + LLM para desarrollar un chatbot sobre ansiedad y depresiÃ³n no solo mejora la calidad y seguridad de las respuestas, sino que ademÃ¡s ofrece una soluciÃ³n tÃ©cnica Ã©tica, escalable y centrada en el bienestar del usuario. Esta herramienta no pretende reemplazar el acompaÃ±amiento profesional, sino funcionar como una guÃ­a accesible, informada y confiable que ayude a reducir barreras, brindar contenciÃ³n y facilitar el acceso a recursos de salud mental adecuados.\n",
    "\n",
    "A continuaciÃ³n se presenta una propuesta desarrollada con **fines exclusivamente educativos**. Por ello, las respuestas generadas deben ser interpretadas como orientaciones generales y no deben considerarse asesoramiento mÃ©dico, diagnÃ³stico clÃ­nico ni sustituto de atenciÃ³n profesional. Se recomienda que los usuarios consulten a especialistas en salud mental ante cualquier duda o situaciÃ³n que requiera intervenciÃ³n profesional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQL0S7wX54Vh"
   },
   "source": [
    "# **Paquetes y librerÃ­as**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmeyvDTjBGHV"
   },
   "source": [
    "## ğŸ” Procesamiento de Lenguaje Natural (NLP)\n",
    "* **ğŸ“š transformers:**  Biblioteca de modelos preentrenados desarrollada por Hugging Face. Permite usar modelos de NLP como BERT, GPT, T5, etc., para tareas como clasificaciÃ³n, resumen, traducciÃ³n, y mÃ¡s.\n",
    "\n",
    "* **ğŸ§  sentence-transformers:** ExtensiÃ³n sobre transformers enfocada en generar representaciones vectoriales (embeddings) de oraciones y pÃ¡rrafos. Ideal para tareas como bÃºsqueda semÃ¡ntica, comparaciÃ³n de textos y clustering.\n",
    "\n",
    "* **ğŸ“Š datasets:** ColecciÃ³n de datasets estandarizados de Hugging Face para NLP. Simplifica la carga, preprocesamiento y uso de datos para entrenamiento y evaluaciÃ³n de modelos.\n",
    "\n",
    "## ğŸ“¦ VectorizaciÃ³n y BÃºsqueda SemÃ¡ntica\n",
    "* **ğŸ§­ faiss-cpu:** Biblioteca de bÃºsqueda eficiente de vectores desarrollada por Facebook AI. Se usa para encontrar rÃ¡pidamente los elementos mÃ¡s cercanos en grandes conjuntos de embeddings.\n",
    "\n",
    "## ğŸ–¼ï¸ Interfaz de Usuario / Aplicaciones Web\n",
    "* **ğŸ§ª gradio:**\n",
    " Herramienta para crear interfaces web rÃ¡pidas y simples para modelos de machine learning. Ideal para prototipar y compartir modelos con inputs y outputs interactivos, lo cuÃ¡l es perfecto para el Chatbot a desarrollar.\n",
    "\n",
    "## ğŸ“„ Lectura de Documentos PDF\n",
    "* **ğŸ“„ PyMuPDF:** Biblioteca para leer, extraer texto y trabajar con archivos PDF y otros documentos. Muy Ãºtil para convertir PDFs a texto para anÃ¡lisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVMo8aNh595N",
    "outputId": "1b5d6a47-30e8-4a48-8931-10bc4d036f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.1\n"
     ]
    }
   ],
   "source": [
    "# Incluyan a continuaciÃ³n todas las celdas (de cÃ³digo o texto) que deseen...\n",
    "!pip install transformers\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install gradio\n",
    "!pip install datasets\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJtWHl5iBMpo"
   },
   "source": [
    "## ğŸ§± Utilidades del Sistema y Datos\n",
    "\n",
    "* **ğŸ“‚ os:** MÃ³dulo estÃ¡ndar de Python para interactuar con el sistema operativo. Se usa para operaciones como navegar entre carpetas, crear directorios o manipular archivos.\n",
    "\n",
    "* **ğŸ“¦ pickle:** Biblioteca estÃ¡ndar de Python para serializar y deserializar objetos. Ãštil para guardar modelos, datos procesados o estructuras en archivos binarios para reutilizaciÃ³n.\n",
    "\n",
    "* **ğŸ”¢ numpy:** Paquete fundamental para computaciÃ³n numÃ©rica en Python. Permite manejar arrays y realizar operaciones matemÃ¡ticas eficientes a nivel de matriz.\n",
    "\n",
    "* **ğŸŒ IPython.display:** Importamos las funciones `display` y `HTML` para desplegar contenido enriquecido como HTML dentro de celdas de Google Colab.\n",
    "\n",
    "* **ğŸ”¡ re:** MÃ³dulo de expresiones regulares en Python. Se usa para buscar, reemplazar o dividir texto mediante patrones definidos.\n",
    "\n",
    "## ğŸ“„ Procesamiento de Documentos PDF\n",
    "\n",
    "* **ğŸ“„ fitz (PyMuPDF):** Interfaz principal de la biblioteca PyMuPDF. Permite abrir, leer y extraer texto o imÃ¡genes de archivos PDF y otros documentos.\n",
    "\n",
    "## ğŸ“¦ BÃºsqueda SemÃ¡ntica\n",
    "\n",
    "* **ğŸ§­ faiss:** Biblioteca de Facebook AI para bÃºsqueda rÃ¡pida de vectores en grandes volÃºmenes de datos. Se usa para tareas de similitud semÃ¡ntica y recuperaciÃ³n de informaciÃ³n basada en embeddings.\n",
    "\n",
    "## ğŸ” Procesamiento de Lenguaje Natural (NLP)\n",
    "\n",
    "* **ğŸ§  sentence-transformers:** Biblioteca que permite generar embeddings semÃ¡nticos de textos. Generalmente utilizada para tareas como clustering, recuperaciÃ³n semÃ¡ntica y comparaciÃ³n de oraciones.\n",
    "\n",
    "* **ğŸ§¬ transformers (AutoTokenizer, AutoModelForSeq2SeqLM, pipeline):** Componentes clave de la librerÃ­a Hugging Face Transformers:\n",
    "  - **AutoTokenizer:** Convierte texto a tokens entendibles por modelos.\n",
    "  - **AutoModelForSeq2SeqLM:** Carga modelos preentrenados para tareas de secuencia a secuencia.\n",
    "  - **pipeline:** Interfaz simplificada para aplicar tareas comunes con modelos preentrenados.\n",
    "\n",
    "* **ğŸ—£ï¸ nltk & sent_tokenize:** `nltk` es una biblioteca para procesamiento de lenguaje natural. En este caso, se utiliza para **tokenizar texto en oraciones** mediante `sent_tokenize`, Ãºtil para dividir grandes textos en unidades mÃ¡s manejables.\n",
    "\n",
    "## ğŸ“ NormalizaciÃ³n de Vectores\n",
    "\n",
    "* **ğŸ“ normalize:** Se utiliza para escalar vectores de forma que tengan una norma unitaria. Es esencial para calcular similitudes de forma coherente entre vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2KsDfQ0BUh_",
    "outputId": "ebd1fe17-b0c5-4a9e-c474-72a2a8d5f4a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from IPython.display import display, HTML\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tthhwfJhBo0o"
   },
   "source": [
    "## ğŸ“‚ Archivos PDF y sus descripciones\n",
    "\n",
    "A continuaciÃ³n se enlistan los archivos a utilizar para el chatbot, junto con su tema principal y una berve descripciÃ³n de su conrtenido.\n",
    "\n",
    "**1. empatia_comunicacion.pdf**\n",
    "* Tema: EmpatÃ­a en la comunicaciÃ³n\n",
    "* DescripciÃ³n: Describe el concepto de empatÃ­a desde el punto de vista cognitivo y emocional, destacando la importancia de las neuronas espejo y cÃ³mo la empatÃ­a mejora la calidad de la comunicaciÃ³n interpersonal. Incluye tÃ©cnicas como la escucha activa, actitud de apertura y rechazo de prejuicios\n",
    "\n",
    "\n",
    "**2. primeras-paginas-lo-mejor-de-tu-vida-es.pdf**\n",
    "* Tema: Autoestima y confianza personal\n",
    "* DescripciÃ³n: Fragmento del libro de Ma. JesÃºs Ãlava Reyes. Enfatiza la importancia de confiar en uno mismo para alcanzar la felicidad. Incluye reflexiones, testimonios y capÃ­tulos orientados al desarrollo de la autoconfianza y la superaciÃ³n del sufrimiento emocional\n",
    "\n",
    "\n",
    "**3. Guia de Primeros Auxilios PsicolÃ³gicos_Integra.pdf**\n",
    "* Tema: Primeros Auxilios PsicolÃ³gicos (PAP)\n",
    "* DescripciÃ³n: GuÃ­a orientada a personas en movilidad humana. Explica quÃ© es una crisis psicolÃ³gica, cÃ³mo se manifiesta, tipos de intervenciÃ³n, principios del PAP, y autocuidado del personal interviniente. Incluye tÃ©cnicas como escucha empÃ¡tica, estabilizaciÃ³n y contenciÃ³n emocional\n",
    "\n",
    "\n",
    "**4. depresion.pdf**\n",
    "* Tema: DepresiÃ³n\n",
    "* DescripciÃ³n: Documento del National Institute of Mental Health. Define la depresiÃ³n, sus sÃ­ntomas, causas, tipos (mayor, distimia, estacional, posparto, etc.), diagnÃ³stico y tratamientos (psicoterapia, medicamentos, terapia de estimulaciÃ³n cerebral)\n",
    "\n",
    "\n",
    "**5. Abre-tu-mente-modo-positivo-salud-mental.pdf**\n",
    "* Tema: PromociÃ³n de salud mental en jÃ³venes\n",
    "* DescripciÃ³n: GuÃ­a educativa dirigida a docentes y familias. Aborda temas como salud mental, adolescencia, estilo de vida saludable, relaciones sociales, emociones, inteligencia emocional y prevenciÃ³n de problemas de salud mental.\n",
    "\n",
    "\n",
    "**6. AtencionPrimAmb1988_spa.pdf**\n",
    "* Tema: AtenciÃ³n Primaria Ambiental (APA)\n",
    "* DescripciÃ³n: PublicaciÃ³n de la OPS que presenta el concepto de APA. Ofrece un enfoque holÃ­stico para mejorar el ambiente y la salud pÃºblica. Incluye marco conceptual, principios, problemas ambientales locales, participaciÃ³n ciudadana y organizaciÃ³n de centros APA\n",
    "\n",
    "\n",
    "**7. 9789243548203_spa.pdf**\n",
    "* Tema: Primera Ayuda PsicolÃ³gica (OMS)\n",
    "* DescripciÃ³n: GuÃ­a prÃ¡ctica para trabajadores de campo en situaciones de emergencia. Define PAP, principios de acciÃ³n (observar, escuchar, conectar), cÃ³mo ayudar de forma responsable y cÃ³mo cuidarse como interviniente. Incluye ejercicios y casos simulados\n",
    "\n",
    "\n",
    "**8. empatia.pdf**\n",
    "* Tema: EmpatÃ­a y neurociencia\n",
    "* DescripciÃ³n: PresentaciÃ³n sobre empatÃ­a desde una perspectiva emocional, cognitiva y neurocientÃ­fica.\n",
    "\n",
    "\n",
    "**9. Guiasautoayudadepresionansiedad.pdf**\n",
    "* Tema: Autoayuda para depresiÃ³n y ansiedad\n",
    "* DescripciÃ³n: Conjunto de guÃ­as del Servicio Andaluz de Salud. Contienen informaciÃ³n y actividades sobre depresiÃ³n, ansiedad, duelo, autoestima, control de pensamientos, tÃ©cnicas de relajaciÃ³n, afrontamiento del estrÃ©s, etcÃ©rtera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muh29EoTYcDI"
   },
   "source": [
    "## ğŸ“ CreaciÃ³n de Carpeta y Descarga Condicional de Archivos\n",
    "\n",
    "Este bloque de cÃ³digo verifica si existe una carpeta llamada `pdf` en el entorno (`/content/pdf`) y realiza las siguientes acciones:\n",
    "\n",
    "* ğŸ—‚ï¸ **Crea la carpeta si no existe**, asegurando el espacio necesario para almacenar los archivos PDF.\n",
    "* ğŸ” **Verifica si la carpeta estÃ¡ vacÃ­a**:\n",
    "  - Si estÃ¡ vacÃ­a, **descarga los archivos desde una carpeta pÃºblica en Google Drive** usando `gdown`.\n",
    "  - Si ya contiene archivos, **omite la descarga** para evitar redundancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD_iRBEQcHj9",
    "outputId": "012e1a5e-ede9-42ba-e77f-d7c857575eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Carpeta creada: /content/pdf\n",
      "ğŸ“¥ La carpeta estÃ¡ vacÃ­a. Iniciando descarga de contenidos...\n",
      "Retrieving folder contents\n",
      "Processing file 1kG5IIlGvSiQ0ssXATpeObGRZbFwf58QP 9789243548203_spa.pdf\n",
      "Processing file 1Xjx71RvGUBeujBbI8UKlqrQmq7YHm-ta Abre-tu-mente-modo-positivo-salud-mental.pdf\n",
      "Processing file 1RqMKjObfW74KOjsigrp5yEGyfQ7CHhqc AtencionPrimAmb1988_spa.pdf\n",
      "Processing file 1RY6Te6pvkc_4YpVYnbUBvm___1gpdoH6 depresion.pdf\n",
      "Processing file 1G-pEX_H2UXOZitt7cfjTLZgEAnDmfFIe empatia_comunicacion.pdf\n",
      "Processing file 1wmn6s6ydyh23PFVIdr1UsaQoJDXO7ouk empatia.pdf\n",
      "Processing file 1Yg0JTjMj6UWECVpuOBlB13zMm9pid-J0 Guia de Primeros Auxilios PsicoloÌgicos_Integra.pdf\n",
      "Processing file 1hRSuv2xQ5BurzmlZylc3zB7YzgtWaAil Guiasautoayudadepresionansiedad.pdf\n",
      "Processing file 1yGMaILcMOQmZYkLu0vys0deRj5dqt7UP primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf\n",
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1kG5IIlGvSiQ0ssXATpeObGRZbFwf58QP\n",
      "To: /content/pdf/9789243548203_spa.pdf\n",
      "100% 5.17M/5.17M [00:00<00:00, 32.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Xjx71RvGUBeujBbI8UKlqrQmq7YHm-ta\n",
      "To: /content/pdf/Abre-tu-mente-modo-positivo-salud-mental.pdf\n",
      "100% 3.82M/3.82M [00:00<00:00, 22.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RqMKjObfW74KOjsigrp5yEGyfQ7CHhqc\n",
      "To: /content/pdf/AtencionPrimAmb1988_spa.pdf\n",
      "100% 5.19M/5.19M [00:00<00:00, 35.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RY6Te6pvkc_4YpVYnbUBvm___1gpdoH6\n",
      "To: /content/pdf/depresion.pdf\n",
      "100% 2.81M/2.81M [00:00<00:00, 20.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1G-pEX_H2UXOZitt7cfjTLZgEAnDmfFIe\n",
      "To: /content/pdf/empatia_comunicacion.pdf\n",
      "100% 195k/195k [00:00<00:00, 3.97MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wmn6s6ydyh23PFVIdr1UsaQoJDXO7ouk\n",
      "To: /content/pdf/empatia.pdf\n",
      "100% 23.6M/23.6M [00:00<00:00, 60.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yg0JTjMj6UWECVpuOBlB13zMm9pid-J0\n",
      "To: /content/pdf/Guia de Primeros Auxilios PsicoloÌgicos_Integra.pdf\n",
      "100% 941k/941k [00:00<00:00, 9.80MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hRSuv2xQ5BurzmlZylc3zB7YzgtWaAil\n",
      "To: /content/pdf/Guiasautoayudadepresionansiedad.pdf\n",
      "100% 21.5M/21.5M [00:00<00:00, 50.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yGMaILcMOQmZYkLu0vys0deRj5dqt7UP\n",
      "To: /content/pdf/primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf\n",
      "100% 161k/161k [00:00<00:00, 3.82MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "# Crear la carpeta \"pdf\" si es que no existe\n",
    "folder_path = \"/content/pdf\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"âœ… Carpeta creada: {folder_path}\")\n",
    "else:\n",
    "    print(f\"ğŸ“ La carpeta ya existe: {folder_path}\")\n",
    "\n",
    "# Revisar si la carpeta estÃ¡ vacÃ­a y descargar los archivos de la misma. Si no, saltar descarga.\n",
    "if not os.listdir(folder_path):\n",
    "    print(\"ğŸ“¥ La carpeta estÃ¡ vacÃ­a. Iniciando descarga de contenidos...\")\n",
    "    folder_url = \"https://drive.google.com/drive/folders/1WxKzp5YHdhS4hf47zFUScL9FHpRSaexE?usp=sharing\"\n",
    "    !gdown --folder {folder_url} -O {folder_path}\n",
    "else:\n",
    "    print(\"âœ… La carpeta ya tiene contenidos. Se omite la descarga.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9J9Y_yWYlE3"
   },
   "source": [
    "## ğŸ“„ ExtracciÃ³n y VisualizaciÃ³n de Contenido de Archivos PDF\n",
    "\n",
    "Este bloque realiza la lectura, procesamiento y previsualizaciÃ³n del contenido de archivos PDF utilizando PyMuPDF (`fitz`):\n",
    "\n",
    "* **ğŸ“¥ `extract_text_from_pdf(file_path)`**  \n",
    "  FunciÃ³n que **abre un archivo PDF y concatena el texto de todas sus pÃ¡ginas** en un solo string, utilizando `fitz` para extraer el texto pÃ¡gina por pÃ¡gina.\n",
    "\n",
    "* **ğŸ“‚ Procesamiento de archivos PDF**  \n",
    "  Recorre todos los archivos dentro de la carpeta `/content/pdf`, aplica la funciÃ³n anterior y guarda los resultados en un diccionario `pdf_texts` con la estructura `{nombre_archivo: texto_extraÃ­do}`.\n",
    "\n",
    "* **ğŸ‘€ PrevisualizaciÃ³n de contenido**  \n",
    "  Por cada archivo procesado, **muestra los primeros 100 caracteres del contenido extraÃ­do**, lo cual permite verificar rÃ¡pidamente si la extracciÃ³n fue exitosa y si el contenido es legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX3Ea3jlghLf",
    "outputId": "13dd37f6-4e74-4c94-bae4-483a784c050a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[Abre-tu-mente-modo-positivo-salud-mental.pdf]:\n",
      "\n",
      "1\n",
      "GUÃA PARA\n",
      "DOCENTES Y FAMILIAS\n",
      "PROMOCIÃ“N DE SALUD\n",
      "MENTAL EN JÃ“VENES\n",
      "PROMOCIÃ“N DE SALUD MENTAL EN JÃ“\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[Guiasautoayudadepresionansiedad.pdf]:\n",
      "\n",
      "PARA LA DEPRESIÃ“N Y LOS TRASTORNOS DE ANSIEDAD\n",
      "PARA LA DEPRESIÃ“N Y LOS TRASTORNOS DE ANSIEDAD\n",
      "Servic\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[empatia.pdf]:\n",
      "\n",
      "EMPATÃA\n",
      "EL ARTE DE COMPRENDER EMOCIONES\n",
      "EMPATÃA\n",
      "EL ARTE DE COMPRENDER EMOCIONES\n",
      "3\n",
      " Mahatma G a n d h\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[depresion.pdf]:\n",
      "\n",
      "DepresiÃ³n \n",
      " \n",
      "Â¿QuÃ© es la depresiÃ³n?\n",
      "Todas las personas se sienten tristes o decaÃ­das de vez en cuando\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[9789243548203_spa.pdf]:\n",
      "\n",
      "Primera ayuda psicolÃ³gica:  GuÃ­a para trabajadores de \n",
      "campo\n",
      "CatalogaciÃ³n por la Biblioteca de la OM\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[empatia_comunicacion.pdf]:\n",
      "\n",
      "1\n",
      "EmpatÃ­a en la comunicaciÃ³n \n",
      "La empatÃ­a en la comunicaciÃ³n es fundamental para lograr una conexiÃ³n \n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[Guia de Primeros Auxilios PsicoloÌgicos_Integra.pdf]:\n",
      "\n",
      "GuÃ­a de Primeros Auxilios \n",
      "PsicolÃ³gicos (PAP) a personas en \n",
      "situaciÃ³n de movilidad humana\n",
      "GuÃ­a de P\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[primeras-paginas-primeras-paginas-lo-mejor-de-tu-vida-es.pdf]:\n",
      "\n",
      "Lo mejor de tu vida eres tÃº\n",
      "ConfÃ­a en la fuerza de tus emociones\n",
      "M.Âª JesÃºs Ãlava Reyes\n",
      "Ãndice\n",
      "Agrade\n",
      "================================================================================\n",
      ">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[AtencionPrimAmb1988_spa.pdf]:\n",
      "\n",
      "OrganizaciÃ³n Panamericana de la Salud \n",
      "#k' OrganizaciÃ³n Mundial de la Salud \n",
      "DivisiÃ³n de Salud y Amb\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# FunciÃ³n para extraer y concatenar el texto de todas las pÃ¡ginas de un archivo PDF usando PyMuPDF (fitz)\n",
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Procesar todos los archivos PDF subidos\n",
    "pdf_texts = {}\n",
    "for filename in os.listdir(folder_path):\n",
    "      file_path = os.path.join(folder_path, filename)\n",
    "      text = extract_text_from_pdf(file_path)\n",
    "      pdf_texts[filename] = text\n",
    "\n",
    "# Mostrar los primeros 1000 caracteres de un archivo\n",
    "for name, content in pdf_texts.items():\n",
    "    print(f\">>> Desplegando previzualizaciÃ³n del contenido del archivo ğŸ“š[{name}]:\\n\")\n",
    "    print(content[:100])\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVO3U5JxBpDi"
   },
   "source": [
    "## ğŸ§  Carga de Modelo de Embeddings MultilingÃ¼e\n",
    "\n",
    "ğŸ“¦ A continuaciÃ³n se carga un modelo preentrenado de la librerÃ­a `sentence-transformers`, especÃ­ficamente el modelo **`paraphrase-multilingual-MiniLM-L12-v2`**, el cual genera embeddings (representaciones vectoriales) de frases o textos.\n",
    "\n",
    "### âœ… Razones para usar este modelo:\n",
    "* ğŸŒ **MultilingÃ¼e:** Soporta mÃ¡s de 50 idiomas, ideal para trabajar con datos en distintos idiomas sin necesidad de traducir.\n",
    "* âš¡ **Ligero y rÃ¡pido:** Basado en la arquitectura MiniLM, lo que permite un buen equilibrio entre rendimiento y velocidad, incluso sin GPU.\n",
    "* ğŸ” **PrecisiÃ³n en similitud semÃ¡ntica:** Entrenado para tareas como detecciÃ³n de parÃ¡frasis y bÃºsqueda semÃ¡ntica, lo que lo hace muy Ãºtil para clustering, recuperaciÃ³n de texto y comparaciÃ³n de oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "9b3646b558f545498dcd5429336f7169",
      "0618b98517e240018ab0972bd9ac4ba8",
      "7aea9e18466348888b06c7c3950946c9",
      "49138a3b27e04b8eab92d943709470aa",
      "71ee4a913fb64c9789d0d521b93047d0",
      "87df9319173b4b90862c0d62a34f823f",
      "ad8179b1d9e54343952e1dd17aebf92e",
      "1a70f78119a745468d16aefc3802e311",
      "16b0f0fcb1b248a7949792153c9fc20a",
      "36bacd460b534e2cbe0ef86d2d17a27d",
      "95dcf090bb304dc180304a9e86989457",
      "aa2fcb8d91a14293bd52beff8d2020e3",
      "f121a29e42294ef78c670a3451c9b399",
      "df65358d91114284bf8a85cc62494043",
      "1373e4b8cc8740af986ec61e7831d7e5",
      "f742685383154fbc9cb1a94fb458379d",
      "000b7d0d436a46a7b6d5f78996bc115f",
      "390d11797fbf4c6f958c88190de17d2b",
      "7e116f0e3e404a668770f3b4066e47fd",
      "7edc739eeeff4080b4c09be62f8bf8ec",
      "15d519648e77400e9e210a0c50bb9288",
      "0ee24a0125d54931a3d7544e4d21f513",
      "bf4c68dc74974082ad94453a012db125",
      "b4e78cfefa0047c08df8b8f5942077f1",
      "368aefd612ec45b584b09533b5e3ee92",
      "03cef043ed414db387b1414262bdbad1",
      "32b4efbca4d84df1a2683215f03d48b5",
      "94d3525ccca8406da544946dff67b04c",
      "152ca56933364c39a3e9e15b5d2e65df",
      "d2adf9a4d0f941a19ded9eabd0ef29bb",
      "b1bf7b16a08b440d9f5259d2067445f1",
      "84d35ab60bef4655b628fa72e9ed8bd4",
      "18fc681c61764f2b94074c85eeb73f68",
      "cd03aa48a73542bd8d9cc56fd246314f",
      "aa83c058181d4753beea094a273836e9",
      "8a09deb27b0f49f8bf8bdbe7efb2530b",
      "f2b5540313dc4594b001b5cfff8ddf3e",
      "83f9fc21839249cc936221a30280e07f",
      "a94041031c9d4cc085687cff11dacce5",
      "43626c91740c4d5480f286c616ec7470",
      "33ef6555e2bc4050a1dab8788e4c8d1d",
      "03e4e195fb744d45a0c30f3f54e12d64",
      "15eb4427128b4424a0aac0adaf7b6767",
      "b6a8613fe399410db23aa98dc33cc3f6",
      "87fa77276502479f83c7fdb15a84edb2",
      "e503e49ede334abdaf30a7841edcf28d",
      "69f6e71badf1433eaf609ccb9284daa9",
      "91fb85dbe216434ea6c5c7b77cddc751",
      "3dd69d4051464345b420068164fa3051",
      "a3c570a272d84f2d97f28698328099f2",
      "7e0aed0160ff46da99a6ddf347cbe2e4",
      "575d20fd1121483b89c1a557dcd2f71b",
      "66eb269400c9462e9beb82c2af2e3882",
      "3cae67185fdf40609531a4ed48de8037",
      "5e0a46a193bf4dde9fd588846c029573",
      "af8eae2777394f1380d0273dd4d16202",
      "4f25f35f329f4e389073e35760a67b52",
      "e1c81fca72374fb99740a7bcbc9c7f27",
      "c5e50468b9bc4423a5ecca2b909277d2",
      "03c29f49a4d44ba2b7adfc7c43c1d135",
      "053c265e51df4eec81e15e9f0500cd44",
      "f0e0d0d76d9c4ca49fafd658e0008370",
      "e2f3c03265c14db3848bc644cfabc6e5",
      "5932bfaec9e74cad805d637eafb54aec",
      "74ca065c1e074e60a486ded4049487d6",
      "674e717dc9324e81a821f3749889da59",
      "92668f0f32ef472197896d7fcc2c8a9f",
      "6463e6ede4e747bd88aeb4ca442460cd",
      "15738ceb38ac470282e7d8487f0d99a0",
      "7173153c432c4dccb29334dbb46717a9",
      "6e85b583a2cf4cbbba0403b6e9daee22",
      "d7eb89941e1147289a2c76ffd7b50f74",
      "752fd035d6d64014b0b2ab73e16f455e",
      "8420bc68121545c7b5bfac2bb53e276b",
      "22e118951b564830a2c262108b361dff",
      "11bcf136ce044cc296c9f5dfec2552c4",
      "f7c66725ddd54ef98d102b43d9548531",
      "9ee7d3f935d84ffc8feb61fa5c415591",
      "d9f96e29c1a74f868899e34ab912fb8e",
      "76d8acec01c74734826738b7231eeca0",
      "9bd44661cc414a3d908add9c254a09da",
      "67873295d68249818667aa39acb441fe",
      "02ea5bdf05904a38b06b2c90fbf258fd",
      "1b108c391dd045b5be9ab809a1bc8f58",
      "630513d8e247409ebd2bb990aff53754",
      "f4d7ac2cb1954c808de5a0b6b6921806",
      "3bc510395f04452b9ae2a04a02b15575",
      "c0e2334e60474406b57782be17b913f2",
      "a7cc8d3bcb574fc090556edae1cdb2fd",
      "d7969077ff0849289c7a2871eaa147bf",
      "d44ba7da17684529ba85e060c119ffc2",
      "f60fd2ad299449d5876a80a82a883cd3",
      "576eb5e5f93a438ea30f15ba5942621d",
      "7f12ce385e27461ca86b4a5b486640c6",
      "699ba136386f4f84aaded5fd10172d87",
      "18773767be0b4b93b5f37b0e187501ed",
      "33ecb204613f427eac169b021eafa832",
      "5aff11958f3e40909f98a2173826b4e6",
      "495cbe4df4eb4807a606c48d3f503a87",
      "58148bb516c7442998830f314efa97cd",
      "3ded8250fceb4c0ba78775ce43b2cd19",
      "3629940986f043119c34d4e17de1a282",
      "186f4fa730074869943698cd96249482",
      "b749ee736d164df19175adfef48be174",
      "af981b27cf0c421bb6416fc1291cbd97",
      "fc26faafedfd4baea370dc3928061015",
      "8ee2dda7b271422682c5a9cb93009694",
      "27be9dc7382b4d01bebae1af5c444668",
      "17ecb717cb084651ad19d8b1091e3e28",
      "d9a7558f8469467eb91780aa4df35058",
      "0feb9eb1caf848b7a6e0dd66516a7f1f",
      "41ee32047b174eeb98c22e6038a12da5",
      "266078bb14b84e93a2c304a074f7ddc0",
      "45b276f61e544dc4a48cf41a30b9a0ea",
      "c72ea4d7f2f4426495c9700d18b5e1ee",
      "ddf9c7eb216e476cba6d85c4e6552833",
      "e1641e29d1eb44f2b956b0b746465821",
      "850e073e44bc4e5692ecd4fdb83e2afc",
      "24a6bac1974b40ff9a078f09b490a415",
      "1a38367bd7904d8f98c24b017b25f7cf",
      "4828b71f8c52474a8c9960fbb429267e"
     ]
    },
    "id": "Bfs5Zxc9j7Uf",
    "outputId": "14896e80-9fc7-408d-c97e-0d3b917c2ae1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3646b558f545498dcd5429336f7169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2fcb8d91a14293bd52beff8d2020e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4c68dc74974082ad94453a012db125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd03aa48a73542bd8d9cc56fd246314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fa77276502479f83c7fdb15a84edb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8eae2777394f1380d0273dd4d16202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92668f0f32ef472197896d7fcc2c8a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee7d3f935d84ffc8feb61fa5c415591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cc8d3bcb574fc090556edae1cdb2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58148bb516c7442998830f314efa97cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feb9eb1caf848b7a6e0dd66516a7f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargando modelo preentrenado\n",
    "model_sentence = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqHZsyC_ZmNK"
   },
   "source": [
    "## âœ‚ï¸ DivisiÃ³n SemÃ¡ntica de Texto por Oraciones\n",
    "\n",
    "Esta funciÃ³n divide un texto en fragmentos **respetando los lÃ­mites de tokens y las fronteras semÃ¡nticas de las oraciones**, usando `sent_tokenize()` de NLTK.\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "* ğŸ§  Divide el texto en oraciones individuales.\n",
    "* ğŸ“¦ Agrupa las oraciones en bloques cuya **longitud no supere `max_tokens` (por defecto 25 palabras)**.\n",
    "* ğŸ” Aplica **solapamiento configurable (`overlap`)** entre bloques, preservando coherencia contextual entre fragmentos.\n",
    "* âœ… Devuelve una lista de bloques listos para anÃ¡lisis semÃ¡ntico, embeddings o respuestas de chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QRStndlYL_hD"
   },
   "outputs": [],
   "source": [
    "# CHUNKING SEMANTICO CON NLTK\n",
    "# FunciÃ³n para dividir el texto en fragmentos (oraciones)\n",
    "def split_text_semantic(text, max_tokens=100, overlap=1):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "    for sentence in sentences:\n",
    "        token_count = len(sentence.split())\n",
    "        if current_len + token_count > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = current_chunk[-overlap:] if overlap > 0 else []\n",
    "            current_len = sum(len(s.split()) for s in current_chunk)\n",
    "        current_chunk.append(sentence)\n",
    "        current_len += token_count\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# FunciÃ³n para dividir el texto en fragmentos (chunks) - NOT USED\n",
    "def split_text(text, chunk_size=500, overlap=50): ##chunk_size=5000, overlap=50)\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsckZ09AxzBA"
   },
   "source": [
    "## ğŸ§  FragmentaciÃ³n, VectorizaciÃ³n y CreaciÃ³n del Ãndice SemÃ¡ntico\n",
    "\n",
    "* **Fragmenta textos PDF, genera sus embeddings y construye un Ã­ndice FAISS para habilitar bÃºsquedas semÃ¡nticas en un chatbot.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ§© **FragmentaciÃ³n semÃ¡ntica de documentos**  \n",
    "  Recorre los textos extraÃ­dos de los PDFs y los divide en fragmentos utilizando `split_text_semantic`, que respeta los lÃ­mites de oraciÃ³n y evita cortes arbitrarios. Luego, cada fragmento se guarda junto con su metadato correspondiente (nombre del archivo y contenido del fragmento).\n",
    "\n",
    "* ğŸ§¬ **GeneraciÃ³n y normalizaciÃ³n de embeddings**  \n",
    "  Los fragmentos generados se convierten en vectores semÃ¡nticos (embeddings) mediante un modelo de `sentence-transformers`. A continuaciÃ³n, se normalizan para que todos tengan norma unitaria, lo cual es necesario para aplicar similitud coseno correctamente.\n",
    "\n",
    "* ğŸ§­ **ConstrucciÃ³n del Ã­ndice FAISS**  \n",
    "  Se crea un Ã­ndice FAISS utilizando `IndexFlatIP`, diseÃ±ado para trabajar con similitud coseno entre vectores normalizados. Luego se agregan todos los embeddings al Ã­ndice para habilitar bÃºsquedas rÃ¡pidas y precisas.\n",
    "\n",
    "Este flujo pemrite que el chatbot pueda realizar bÃºsquedas semÃ¡nticas inteligentes y responder preguntas con base en el contenido de mÃºltiples documentos PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8b19144f2f7145f6a3b3b946c30bddad",
      "4ebb2c3b3e9140438cbb7fcbd34ddfe5",
      "8a67a50a18ef4c78bac14e43cd4b4371",
      "02364584bc3b4663b1644db065ca74fc",
      "9e0947ab1d324c55a61b36c427c43eec",
      "a91916d3fca84b75a02e7dd8ebb01b0c",
      "c202688a729447569667957233e1e202",
      "6f7899451a8a4b27b86c2a2b47598cef",
      "45f35d6642a940448ea6fdab19f048c4",
      "11d5276c130e49ebaf3eb73a9bc26bb0",
      "02226dde735546348ab414cbfd9569f6"
     ]
    },
    "id": "CikjqV0MiO0L",
    "outputId": "dc6d0ded-cebd-4d91-913b-0eb941dc8cb7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b19144f2f7145f6a3b3b946c30bddad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recorrer todos los archivos PDF, divide su contenido en fragmentos,\n",
    "# y guarda tanto los textos como los metadatos (nombre del archivo y texto del fragmento)\n",
    "all_chunks = []\n",
    "metadata = []\n",
    "for filename, text in pdf_texts.items():\n",
    "    #chunks = split_text(text)\n",
    "    chunks = split_text_semantic(text)\n",
    "    all_chunks.extend(chunks)\n",
    "    metadata.extend([{\"source\": filename, \"text\": chunk} for chunk in chunks])\n",
    "\n",
    "# Crear embeddings\n",
    "embeddings = model_sentence.encode(all_chunks, show_progress_bar=True)\n",
    "embeddings = normalize(embeddings, axis=1)  # normalizar para usar cosine similarity (IndexFlatIP)\n",
    "\n",
    "# Crear Ã­ndice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "#index = faiss.IndexFlatL2(dimension)\n",
    "index = faiss.IndexFlatIP(dimension) # Se usa IndexFlatIP oara cosine similatiry\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLr68Bo-yI9T"
   },
   "source": [
    "## ğŸ’¾ Guardado del Ãndice y Metadatos\n",
    "\n",
    "* **Guarda el Ã­ndice FAISS y los metadatos para reutilizarlos sin reprocesar los documentos.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ§­ **Guardar el Ã­ndice FAISS**  \n",
    "  Se almacena el Ã­ndice generado en un archivo `.faiss`, lo que permite reutilizarlo en futuras sesiones sin tener que volver a generar todos los embeddings y reconstruir el Ã­ndice desde cero.\n",
    "\n",
    "* ğŸ—‚ï¸ **Guardar los metadatos**  \n",
    "  Los metadatos (informaciÃ³n del fragmento y su documento de origen) se guardan en un archivo `.pkl` usando `pickle`. Esto es esencial para que, al recuperar un fragmento desde el Ã­ndice, el chatbot pueda identificar de quÃ© archivo proviene y mostrarlo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "t4fkfNKljEhv"
   },
   "outputs": [],
   "source": [
    "# Guardar FAISS index\n",
    "faiss.write_index(index, \"chatbot_index.faiss\")\n",
    "\n",
    "# Guardar los metadatos\n",
    "with open(\"chatbot_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF87r29u5glB"
   },
   "source": [
    "# **Sistema RAG + LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eLAz39byWFB"
   },
   "source": [
    "Un sistema **RAG** (Retrieval-Augmented Generation) es una arquitectura de inteligencia artificial que combina recuperaciÃ³n de informaciÃ³n con generaciÃ³n de texto, con el objetivo de mejorar la precisiÃ³n, relevancia y actualidad de las respuestas generadas por modelos de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqrMSMxG42ZJ"
   },
   "source": [
    "## ğŸ§  Modelos LLM y de Embeddings\n",
    "\n",
    "* **Carga un modelo de lenguaje para generaciÃ³n de respuestas y un modelo de embeddings para comprensiÃ³n semÃ¡ntica.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ’¬ **Modelo generador de respuestas (LLM)**  \n",
    "  Se carga el modelo `google/flan-t5-base`, un modelo de tipo encoder-decoder optimizado para tareas text-to-text.  \n",
    "  A travÃ©s de `AutoTokenizer` y `AutoModelForSeq2SeqLM` de `transformers`, se inicializa el modelo junto con su tokenizador, y se configura un `pipeline` de generaciÃ³n de texto (`text2text-generation`).  \n",
    "  Este modelo permite al chatbot **redactar respuestas completas en lenguaje natural** a partir de consultas y contextos.\n",
    "\n",
    "* ğŸ§© **Modelo de embeddings semÃ¡nticos**  \n",
    "  Se carga el modelo `paraphrase-multilingual-MiniLM-L12-v2` de `sentence-transformers`, el cual convierte oraciones o fragmentos de texto en vectores numÃ©ricos.  \n",
    "  Estos vectores permiten comparar significados y buscar respuestas relevantes dentro del Ã­ndice FAISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "d4f44f1b2fa6410ab5fb0f2c65c972d3",
      "c904f9eefdb3478ebcecf64ab559f97c",
      "8a4421de15b144d6b9aad65decd454d3",
      "404f6b093ae241e1b17735befe43c38a",
      "6b05c8d0c106463eaf883a2212811467",
      "fe27b25e4c6b4194b449ec8cddb0c5c7",
      "f7b4e61f43974da39f5e36e9127c8bee",
      "29cd90fbc78343f6ab98fa40246b6a08",
      "f1b2c24a0748444ea0373d6cef47b3f7",
      "eadff9e410b8499e8cc3b44cd1b59c57",
      "89e4cabb24054e848cdf162026d71078",
      "5c842d997cff46e5a225ea32ee23a1b1",
      "41ec7422567948be93c127d6aeadb875",
      "e5fad5192eb047788dbbf75a2da042b2",
      "9a9826b655d045b3964cd39f6e846a9f",
      "1e57c6a89b934fd984dbbf34730ad845",
      "60af7a07db93431f8a7e194f61576461",
      "ee06f8c710094807b4284e5d094fb00c",
      "473e5345684c41c49136063400478fd4",
      "c10b4faefd4b4db0a3cb5f3aa24d7c10",
      "c4bbaeae18014a1eb53b831e33aa5241",
      "6fb8f51d0d884df8a9ca23ff82332946",
      "c9cd2850f886418f98a426a8699600f5",
      "aca206dba6964d65910a6bdc01e76408",
      "22ecc40e33944627b2475b70dadae0e1",
      "884cc738f7df42589858a5ed8a1849b8",
      "2713dbdc3cac4ca0886a4d0cea389727",
      "c7029f2f43264dc484722200d158aac5",
      "e0a837ed23ff4fcb9e7c06d78d1b4e10",
      "ea177420a67243e19f75199b5aae50d9",
      "5046ba79c53d49328a1ac97057e26fd8",
      "b12e52dbb7cf4f2c8bf43a7a1defb022",
      "26562b4f817a428aade85a68aa454a99",
      "a9f976e791df4808901a25479b257b0b",
      "8f7d695968bd4dee8ebb4d17d67dad7e",
      "133d8276fd724a1e8915a4e380f341a3",
      "f716ba3e02f442dd9e6e1c35e8b01c25",
      "289630afecd0405c9b970660fc42b0a4",
      "53413e852da146e5998b72a646f62a95",
      "0f16e649ec8b4c3894c2d209fb777bb8",
      "2f748a315c4e48c4bb5d165a165d37ba",
      "128257f9f2cb4a68aa0e011af78fa188",
      "ac669201fd4f4e60862bcd655ea43c90",
      "93e6f91dd4d74b2cafa4e430e0ddec8c",
      "08371fdd51294a248d883bfe94b4fc68",
      "96ea198135584792af9703c581aac7a2",
      "0362d4f78bcc4d05a77d34f483bcaa6d",
      "c63af50699c54825aed5b91ac3b42375",
      "bd06a9730ccd4d5488581c8e2354bb71",
      "fbc9a32caf77415fb459ffee1faa9876",
      "d149d566e3b84ec482db5ea0c2529fe0",
      "4fe994cc30cf4d4ab7db6e7aa571b1b8",
      "c3a2ec434c28458b97b818f9025f6313",
      "3900b0dc50044346bb46a2240d468e4a",
      "9e09b1893b764b63b7f0fb4a67d09e55",
      "edfc931f9c584aec83ea45bc90c70372",
      "f80c3dba31ca4c4889b3b837a3df28d0",
      "80d465f88f4c413093381e92fc9e920e",
      "44346ca08d3c4cf8bfbd42e6a904aedb",
      "fecb5af5a0934523bd4da364d9d80a9b",
      "1a9c74baa9cd4cb48eaf02721ab634a8",
      "a9d7b169544d4e87b074c194a09259f8",
      "02cb739fa93b44e09f7bbfb587ebdf44",
      "89e45926c5744fa5ba6205b7351f0eca",
      "25af240506d74b2ab5baf1afbb8bdb19",
      "37210d88ce4c4015b81a475d91160f0d",
      "0de6c718b1cd4544b103e82ca5cf212e",
      "06d91052dad84c98bff51ecf08886f49",
      "db8c28d15eb64c94b7a528b4d5637e1d",
      "4cbc655bb4ba4a7492ace271964c56b0",
      "32e2def3095241788c016458c8b3ee69",
      "d151a574b2de432badf0af8cf7c6bf9b",
      "e9c67f6d90964ac8aecac653c91f5c90",
      "935d7445fbc94a54ac6bbd54983c8673",
      "2a6e031cf7f3433b8cfae4b76752a82e",
      "13e4a58e158141e4b993b7d3a7fa69d3",
      "8f5509928e3648c78c3789caf38e35ac"
     ]
    },
    "id": "SsTf0kyInanM",
    "outputId": "8c73c9eb-6277-439b-aaf0-af213ca5b2d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f44f1b2fa6410ab5fb0f2c65c972d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c842d997cff46e5a225ea32ee23a1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cd2850f886418f98a426a8699600f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f976e791df4808901a25479b257b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08371fdd51294a248d883bfe94b4fc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfc931f9c584aec83ea45bc90c70372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de6c718b1cd4544b103e82ca5cf212e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# LLM para generar respuestas\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Modelo para embeddings (vectorizaciÃ³n)\n",
    "embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEm3RbcU5Je0"
   },
   "source": [
    "## ğŸ§  BÃºsqueda SemÃ¡ntica y GeneraciÃ³n de Respuestas\n",
    "\n",
    "* **Estas funciones permiten buscar fragmentos relevantes mediante similitud semÃ¡ntica y generar respuestas con un modelo LLM.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ” **`search_similar_chunks( )`**  \n",
    "  Genera un embedding para la consulta del usuario y lo compara contra el Ã­ndice FAISS para encontrar los fragmentos mÃ¡s relevantes.  \n",
    "  Si no se encuentra ningÃºn resultado con una similitud suficiente (basada en el `threshold`), retorna `None`.  \n",
    "  Si hay coincidencias, devuelve los textos correspondientes desde los metadatos.\n",
    "\n",
    "* ğŸ§© **`build_prompt( )`**  \n",
    "  Construye un mensaje (prompt) combinando los fragmentos de contexto recuperados con la pregunta del usuario.  \n",
    "  Este prompt es lo que se le entrega al modelo generador para que forme una respuesta informada y contextualizada.\n",
    "\n",
    "* ğŸ’¬ **`generate_answer( )`**  \n",
    "  Orquesta el flujo completo: busca los fragmentos mÃ¡s parecidos a la consulta, genera el prompt y produce una respuesta con el modelo `flan-t5-base`.  \n",
    "  Si no se encuentran fragmentos relevantes, devuelve un mensaje de disculpa.\n",
    "\n",
    "* ğŸ’¾ **Carga del Ã­ndice y metadatos**  \n",
    "  Se cargan el Ã­ndice FAISS (`chatbot_index.faiss`) y los metadatos (`chatbot_metadata.pkl`) previamente guardados, para que el sistema estÃ© listo para responder sin tener que reentrenar o reprocesar documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WlVqMthHneso"
   },
   "outputs": [],
   "source": [
    "def postprocess_answer(text):\n",
    "    text = re.sub(r\"[^\\w\\s.,;:Â¡!Â¿?Ã¡Ã©Ã­Ã³ÃºÃ±ÃÃ‰ÃÃ“ÃšÃ‘]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def build_prompt(query, context_chunks):\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = (\n",
    "      \"Usando la siguiente informaciÃ³n, responde en espaÃ±ol:\\n\\n\"\n",
    "      f\"Contexto:\\n\\\"{context}\\\"\\n\\n\"\n",
    "      f\"Pregunta:\\n{query}\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def search_similar_chunks(query, top_k=3, threshold=0.7):\n",
    "    query_embedding = embedder.encode([query])\n",
    "    query_embedding = normalize(query_embedding, axis=1) #Normalizar los embeddings\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    if max(distances[0]) < threshold:\n",
    "      return None\n",
    "\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        results.append(metadata[i]['text'])\n",
    "    return results\n",
    "\n",
    "def generate_answer(query, top_k=3):\n",
    "    chunks = search_similar_chunks(query, top_k=top_k)\n",
    "    if chunks is None:\n",
    "      return \"Lo siento, no encontrÃ© informaciÃ³n suficiente para responder a eso.\"\n",
    "    prompt = build_prompt(query, chunks)\n",
    "\n",
    "    output = generator(prompt, max_new_tokens=256, do_sample=False)\n",
    "    answer = output[0]['generated_text'] + \"[...]\"\n",
    "    return postprocess_answer(answer)\n",
    "\n",
    "# Cargar Ã­ndice\n",
    "index = faiss.read_index(\"chatbot_index.faiss\")\n",
    "\n",
    "# Cargar metadatos\n",
    "with open(\"chatbot_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOfeqsQb5ttD"
   },
   "source": [
    "# **El chatbot, incluyendo ejemplos de prueba.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiyJ8qcM5ltH"
   },
   "source": [
    "## ğŸ¤– Prueba de Consultas al Chatbot\n",
    "\n",
    "* **EvalÃºa una lista de preguntas simuladas y muestra las respuestas generadas.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ§¾ **Lista de preguntas (`queries`)**  \n",
    "  Contiene ejemplos representativos de preguntas que un usuario podrÃ­a hacerle al chatbot, relacionadas con ansiedad, depresiÃ³n y emociones humanas.\n",
    "\n",
    "* ğŸ”„ **Bucle de interacciÃ³n con el chatbot**  \n",
    "  Para cada pregunta:\n",
    "  - Se imprime la consulta.\n",
    "  - Se llama a `generate_answer()` para obtener una respuesta contextual.\n",
    "  - La respuesta se imprime.\n",
    "\n",
    "Este bloque permite probar y validar cÃ³mo responde el sistema a distintas consultas, ideal para demostraciones, testing o debugging del chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t3eNHkfkGvx",
    "outputId": "a5508599-1fcf-48e2-e9dd-89beda3b54d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "CÃ³mo superar la ansiedad?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "Controle su preocupaciÃ³n. Escoja un lugar y una hora para preocuparse. HÃ¡galo en el mismo lugar y a la misma hora todos los das. Dedicique minutos a pensar en las cosas que le preocupan y en lo que puede hacer con respecto a Ã©stas. Trate de no pensar en lo que podra ocurrir. CÃ©ntrese mÃ¡s en lo que en realidad estÃ¡ sucediendo. Luego deje de preocuparse y contine con sus actividades diarias....\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "QuÃ© es ansiedad?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "La palabra ansiedad se utiliza para describir la respuesta mental y fsica que se produce ante situaciones de peligro...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Cuando es grave la ansiedad?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "Cuando no se controla la ansiedad, las personas describen pensamientos como No voy a poder soportarlo, Esto es horrible, Me darÃ¡ un infarto, EnloquecerÃ©. Estos pensamientos pasan por la mente automÃ¡ticamente, como un flash, cuando se estÃ¡ ansioso...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Cuales son los sÃ­ntomas de la ansiedad?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "agitaciÃ³n, tensiÃ³n, irritabilidad, palpitaciones, temblores, sudoraciÃ³n, preocuparse en exceso, dormir mal, falta de concentraciÃ³n, respiraciÃ³n rÃ¡pida, sensaciÃ³n de pellizco en el estÃ³mago y tensiÃ³n muscular...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Como superar la tristeza?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      ". Exprese su sufrimiento y acepte la ayuda Si tiene malas noticias o un contratiempo importante, intente hablarlo con alguien prÃ³ximo y explquele cÃ³mo se siente. A menudo, repasar las experiencias dolorosas varias veces, llorar, y hablar de los problemas con alguien es til y constituye una forma natural que tiene la mente para curarse...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "QuÃ© es una depresiÃ³n?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "El hecho de sentirse triste, deprimido, de tener pensamientos negativos o dificultad para dormir no significa necesariamente que usted sufra una depresiÃ³n...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Cuales son las causas de la depresiÃ³n?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "Trastornos de ansiedad: en general, la existencia de un trastorno de ansiedad previo a la depresiÃ³n o asociado a Ã©sta, aumenta la gravedad de la misma y el riesgo de recada. Abuso de sustancias o fÃ¡rmacos alcohol, fÃ¡rmacos ansiolticos o hipnÃ³ticos o consumo de sustancias tÃ³xicas como el cannabis, Ã©xtasis, cocana, etc:...\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Quieres ser mi amigo?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "Lo siento, no encontrÃ© informaciÃ³n suficiente para responder a eso.\n",
      "============================================================\n",
      ">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\n",
      "Que es un iPhone?\n",
      "\n",
      "++ ğŸ’» Respuesta del chatbot:\n",
      "Lo siento, no encontrÃ© informaciÃ³n suficiente para responder a eso.\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"CÃ³mo superar la ansiedad?\",\n",
    "    \"QuÃ© es ansiedad?\",\n",
    "    \"Cuando es grave la ansiedad?\",\n",
    "    \"Cuales son los sÃ­ntomas de la ansiedad?\",\n",
    "    \"Como superar la tristeza?\",\n",
    "    \"QuÃ© es una depresiÃ³n?\",\n",
    "    \"Cuales son las causas de la depresiÃ³n?\",\n",
    "    \"Quieres ser mi amigo?\",\n",
    "    \"Que es un iPhone?\"\n",
    "           ]\n",
    "\n",
    "for query in queries:\n",
    "  print(f\"=\"*60)\n",
    "  print(f\">> ğŸ‘¨ğŸ»â€ğŸ’» Pregunta realizada:\\n{query}\\n\")\n",
    "  respuesta = generate_answer(query)\n",
    "  print(\"++ ğŸ’» Respuesta del chatbot:\")\n",
    "  print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBUXG3vr56ev"
   },
   "source": [
    "## ğŸ–¼ï¸ Despliegue de Interfaz Interactiva con Gradio\n",
    "\n",
    "* **Por Ãºltimo, se crea una interfaz web simple para interactuar con el chatbot directamente desde el navegador.**\n",
    "\n",
    "### âš™ï¸ Â¿CÃ³mo funciona?\n",
    "\n",
    "* ğŸ”Œ **`chat_interface(question)`**  \n",
    "  Define una funciÃ³n que toma una pregunta como entrada, genera una respuesta utilizando `generate_answer()`, y la retorna. Esta serÃ¡ la funciÃ³n que conecta la interfaz con la lÃ³gica del chatbot.\n",
    "\n",
    "* ğŸ§ª **`gr.Interface(...)`**  \n",
    "  Utiliza la librerÃ­a `Gradio` para crear una interfaz grÃ¡fica mÃ­nima:\n",
    "  - `inputs=\"text\"` permite al usuario ingresar una pregunta en una caja de texto.\n",
    "  - `outputs=\"text\"` muestra la respuesta generada.\n",
    "  - `launch(share=True)` despliega la interfaz y genera un enlace pÃºblico para compartirla fÃ¡cilmente.\n",
    "\n",
    "  ### Captura de interfaz con Gradio:\n",
    "  <img src=\"https://drive.google.com/uc?id=1cyyi2xpzoqWzWiK4OQVcgSx9eUTEwXwx\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QVsp7TrQsvS"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "Lw1bxsYeQrMn",
    "outputId": "852aad07-5537-430d-a6f8-cfb0acd5a1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://3bc1650c952004e3f9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3bc1650c952004e3f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def chat_interface(question):\n",
    "    answer = generate_answer(question)\n",
    "    return answer\n",
    "gr.Interface(fn=chat_interface, inputs=\"text\", outputs=\"text\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx-dZSFJz9cK"
   },
   "source": [
    "\n",
    "# **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w3usdaC0BCj"
   },
   "source": [
    "* #### **Conclusiones de la actividad chatbot LLM + RAG:**\n",
    "\n",
    "**Aprendizajes generales**\n",
    "- Como equipo, logramos implementar un enfoque de Retrieval-Augmented Generation que permitiÃ³ combinar la potencia de los modelos generativos con la precisiÃ³n del sistema de recuperaciÃ³n documental mediante FAISS. Esto demostrÃ³ ser Ãºtil para responder preguntas especÃ­ficas del dominio de salud mental, generando respuestas contextualizadas y coherentes.\n",
    "\n",
    "- Al utilizar corpus en espaÃ±ol y modelos preentrenados compatibles con el idioma, se buscÃ³ la adecuaciÃ³n lingÃ¼Ã­stica del chatbot para usuarios hispanohablantes. Este enfoque nos confirma la importancia de adaptar los modelos LLM a las necesidades culturales y lingÃ¼Ã­sticas de los usuarios.\n",
    "\n",
    "- El prototipo desarrollado tiene potencial para convertirse en una herramienta de apoyo accesible para personas en bÃºsqueda de informaciÃ³n confiable y actualizada relacionada con salud mental.\n",
    "\n",
    "- Se comprendiÃ³ la arquitectura RAG como una soluciÃ³n que combina lo mejor del acceso a informaciÃ³n (retrieval) con la generaciÃ³n fluida de lenguaje natural (LLM).\n",
    "\n",
    "- Se identificÃ³ que los modelos LLM por sÃ­ solos pueden llegar a tener lÃ­mites si no estÃ¡n conectados a una base de conocimiento actualizada o contextual.\n",
    "\n",
    "- El enfoque RAG permitiÃ³ ofrecer respuestas mÃ¡s precisas, relevantes y trazables, especialmente Ãºtil en temas delicados como salud mental.\n",
    "\n",
    "\n",
    "**TÃ©cnicas y Herramientas Implementadas**\n",
    "\n",
    "- Se utilizaron embeddings semÃ¡nticos para representar texto y permitir bÃºsquedas por similitud en lugar de coincidencia exacta de palabras clave.\n",
    "\n",
    "- Se trabajÃ³ con herramientas como FAISS para construir Ã­ndices de recuperaciÃ³n eficientes.\n",
    "\n",
    "- Se aplicÃ³ un umbral de similitud para filtrar respuestas no relacionadas, mejorando la precisiÃ³n del chatbot.\n",
    "\n",
    "- Se integrÃ³ el sistema en una interfaz interactiva mediante Gradio, facilitando la interacciÃ³n con el usuario final.\n",
    "\n",
    "- Se reafirmÃ³ la importancia del preprocesamiento del texto, incluyendo limpieza, normalizaciÃ³n y tokenizaciÃ³n.\n",
    "\n",
    "- Se emplearon modelos preentrenados de HuggingFace Transformers para tareas de generaciÃ³n de texto, en busca de coherencia y naturalidad.\n",
    "\n",
    "- Se comprobÃ³ que los LLM pueden ampliar, matizar o contextualizar mejor la informaciÃ³n cuando se utilizan junto con RAG.\n",
    "\n",
    "- Se logrÃ³ generar respuestas basadas en fuentes especÃ­ficas.\n",
    "\n",
    "- Se apreciaron los beneficos de que es un enfoque modular y escalable, permitiendo incorporar nuevos documentos sin necesidad de reentrenar el modelo.\n",
    "\n",
    "**Retos y Reflexiones**\n",
    "\n",
    "- Se observan oportunidades en las respuestas, ya que hay errores ligeros en cuanto a formato, idiomas y gramÃ¡tica. Algunas opciones para mejorarlo pudiera ser hacer un proceso de limpieza mÃ¡s extensivo, aplicar filtros de idioma, post-procesamiento mÃ¡s complejo de la respuesta o incluso usar modelos mÃ¡s pesados, robustos y potentes que usualmente son de paga.\n",
    "\n",
    "- Se identificÃ³ que definir un umbral de similitud adecuado es clave para evitar respuestas irrelevantes y se identificÃ³ como `top_k` y `max_new_tokens` aon claves para generar respuestas coherentes.\n",
    "\n",
    "- Se recalca la importancia de hacer un prompt correcto. En nuestro caso particular, generÃ³ una gran diferencia hacer el prompt en inglÃ©s, esto probablemente debido a la preferencia del modelo pre-entrenado seleccionado por el idioma. Solicitar la respuetsa en espaÃ±ol y pedir eliminar errores tambien mostrÃ³ una mejora significativa en la calidad de la respuesta.\n",
    "\n",
    "- Se observÃ³ que la curaciÃ³n del corpus (selecciÃ³n y fragmentaciÃ³n del contenido) tiene un impacto directo en la calidad del chatbot. La selecciÃ³n de documentos debe ser un proceso realizado con cuidado.\n",
    "\n",
    "- Se concluyÃ³ que este enfoque puede adaptarse a otros dominios como educaciÃ³n, derecho, atenciÃ³n mÃ©dica o servicio al cliente.\n",
    "\n",
    "- Se reconociÃ³ que la estructura RAG es multilingÃ¼e y adaptable, facilitando su implementaciÃ³n en diversos contextos.\n",
    "\n",
    "- Se evidenciÃ³ el potencial para escalar esta tecnologÃ­a hacia sistemas mÃ¡s complejos como tutores virtuales, asistentes personales o motores de bÃºsqueda especializados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLCGSshm7k9j"
   },
   "source": [
    "# Referencias\n",
    "\n",
    "### Referencias\n",
    "\n",
    "* Amazon Web Services (AWS). (2025). *Â¿QuÃ© es la generaciÃ³n aumentada por recuperaciÃ³n (RAG)?*. Recuperado de https://aws.amazon.com/es/what-is/retrieval-augmented-generation/\n",
    "* DeepLearning.AI. (2024). *LangChain for LLM Application Development*. Recuperado de https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\n",
    "* Google Cloud. (2025). *Uso de RAG: casos de uso de generaciÃ³n aumentada por recuperaciÃ³n*. Recuperado de https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=es\n",
    "* Gradio. (2025). *Quickstart Guide for Gradio: construir y compartir demos de ML en Python*. Recuperado de https://www.gradio.app/guides/quickstart\n",
    "* Hohls, J. K., KÃ¶nig, H.-H., Quirke, E., & Hajek, A. (2021). Anxiety, Depression and Quality of Life--A Systematic Review of Evidence from Longitudinal Observational Studies. *International Journal of Environmental Research and Public Health*, *18*(22), 12022. https://doi.org/10.3390/ijerph182212022\n",
    "* Hua, Y., Na, H., Li, Z., & et al. (2025). A scoping review of large language models for generative tasks in mental health care. *npj Digital Medicine*, *8*, 230. https://doi.org/10.1038/s41746-025-01611-4\n",
    "* O'Reilly Media. (2025). *Retrievalâ€‘Augmented Generation (RAG) and LLMs*. Recuperado de https://www.oreilly.com/live-events/retrieval-augmented-generation-rag-and-llms/0790145078618/\n",
    "* Palomares, I. (2024). *Boost LLM Accuracy with Retrieval Augmented Generation (RAG) & Reranking*. Recuperado de https://www.datacamp.com/es/tutorial/boost-llm-accuracy-retrieval-augmented-generation-rag-reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtB5Q3m41YQ0"
   },
   "source": [
    "# **Fin de la actividad chatbot: LLM + RAG**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
