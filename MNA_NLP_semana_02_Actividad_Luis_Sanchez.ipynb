{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**\n",
        "### Alumno: Luis Gerardo Sánchez Salazar\n",
        "Matrícula: A01232963"
      ],
      "metadata": {
        "id": "759SG4TyfbUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ .\n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ],
      "metadata": {
        "id": "6ue1YAKx3XDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ],
      "metadata": {
        "id": "Zj-h4drXD-X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios.\n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ],
      "metadata": {
        "id": "BY6yifxscfrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ],
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se descarga archivo .txt de Google Drive a la carpeta raíz y se renombra\n",
        "!gdown https://drive.google.com/uc?id=1MRNGuIJJDtz1pTHDq5AY9sVATxMpBtIf -O MNA_NLP_semana_02_Actividad_datos.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZkk53yHt_Eg",
        "outputId": "2e46bbe4-0841-420c-e8ee-0cda98670929"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MRNGuIJJDtz1pTHDq5AY9sVATxMpBtIf\n",
            "To: /content/MNA_NLP_semana_02_Actividad_datos.txt\n",
            "\r  0% 0.00/59.9k [00:00<?, ?B/s]\r100% 59.9k/59.9k [00:00<00:00, 53.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt',        # puedes actualizar la ruta a tu archivo, en dado caso.\n",
        "          mode='r',     # abrimos el archivo en modo lectura.\n",
        "          ) as f:\n",
        "    docs = f.readlines()    # separamos cada comentario por líneas\n",
        "\n",
        "f.close()  # ya que tenemos la información en la variable docs, cerramos el archivo"
      ],
      "metadata": {
        "id": "QHUmJyjDdGNP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ],
      "metadata": {
        "id": "L6WzrSrodG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c03e9c-77ea-4bdf-92be-b4b0a2088734"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ],
      "metadata": {
        "id": "QIK1u9WS2FtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e56258e-9e29-4dba-aeb2-cc43711b5691"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ],
      "metadata": {
        "id": "9AMLIfQvJqNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d183541b-b093-4a13-c680-6f0e25a584b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.\\n',\n",
              " 'Crust is not good.\\n',\n",
              " 'Not tasty and the texture was just nasty.\\n',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n',\n",
              " 'The selection on the menu was great and so were the prices.\\n',\n",
              " 'Now I am getting angry and I want my damn pho.\\n',\n",
              " \"Honeslty it didn't taste THAT fresh.)\\n\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n',\n",
              " 'The fries were great too.\\n',\n",
              " 'A great touch.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ],
      "metadata": {
        "id": "k_ewoagic5jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ],
      "metadata": {
        "id": "X-eMJa3DFCIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 1.**\n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario.\n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ],
      "metadata": {
        "id": "78nJMemzn5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de despliegue de resultados\n",
        "# Se crea una función que toma como argumentos la lista de resultados, el número de entradas a desplegar y una opción para\n",
        "# desplegar la cantidad de resultados únicos\n",
        "# Esta función se utilizará para presentar los resultados de cada una de las preguntas del ejercicio\n",
        "def desplegar_resultados(lista, num_resultados=None, unique=False):\n",
        "  print(f\"==\"*30)\n",
        "  print(f\"Total de resultados encontrados: {len(lista)}\")\n",
        "  print(f\"==\"*30)\n",
        "  if num_resultados is None:\n",
        "    num_resultados = len(lista)\n",
        "    text = \"Despliegue de resultados:\"\n",
        "  else:\n",
        "    text = f\"Primeros {num_resultados} Resultados:\"\n",
        "\n",
        "  if unique == True:\n",
        "    print(f\"Resultados únicos encontrados: {len(set(lista))}\")\n",
        "    print(f\"==\"*30)\n",
        "    for count, sentence in enumerate(set(lista[:num_resultados])):\n",
        "      print(f\"[{count + 1}]: {sentence}\")\n",
        "  else:\n",
        "      print(text)\n",
        "      print(f\"==\"*30)\n",
        "      for count, sentence in enumerate(lista[:num_resultados]):\n",
        "        print(f\"[{count + 1}]: {sentence}\")"
      ],
      "metadata": {
        "id": "qGdZz6zsmhva"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para esta pregunta, se utilizará list comprehension\n",
        "# p1 almacenará una lista con las 1000 entradas contenidas en docs\n",
        "# Sin embargo, estas ya estarán procesadas de la siguiente manera:\n",
        "#  *** re.sub() - Se utilizará para sustituir los saltos de línea (\\n) con espacios vacíos ('')\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw) para que considere los caracteres \\n como caracteres regulares dentro del texto\n",
        "#  *** \\n - Corresponde el caracter a buscar\n",
        "#  *** '' - Corresponde al caracter que se usará para reemplazar\n",
        "p1 = [re.sub(r'\\n', '', w) for w in docs]\n",
        "desplegar_resultados(p1,num_resultados=10)"
      ],
      "metadata": {
        "id": "PwbYYIuZn8pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66eb4ec3-d5c5-4c9a-8dd4-3c7978aa6906"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 1000\n",
            "============================================================\n",
            "Primeros 10 Resultados:\n",
            "============================================================\n",
            "[1]: Wow... Loved this place.\n",
            "[2]: Crust is not good.\n",
            "[3]: Not tasty and the texture was just nasty.\n",
            "[4]: Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
            "[5]: The selection on the menu was great and so were the prices.\n",
            "[6]: Now I am getting angry and I want my damn pho.\n",
            "[7]: Honeslty it didn't taste THAT fresh.)\n",
            "[8]: The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\n",
            "[9]: The fries were great too.\n",
            "[10]: A great touch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\".\n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ],
      "metadata": {
        "id": "VWeKQC93ctEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p2 engloba una lista que contiene tuplas con el resultado (palabra) y la cantidad de \"!\" encontrados.\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (for w in p1) recorre cada comentario (string) dentro de p1\n",
        "# El segundo (for match in re.finditer( ), w), cada coincidencia encontrada en la expresión definida se agregará a la lista p2 (el resultado es un objeto match)\n",
        "# La expresión a buscar se describe a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\w+ - Busca conjuntos de caracteres alfanuméricos (es decir, la palabra tal cual)\n",
        "#  *** (!{2,}) - Indica que seguido de la palabra, debe haber al menos dos \"!\" consecutivos (también se puede usar !!+)\n",
        "#  *** NOTA: Es importante destacar el uso de los paréntesis (), pues estos agrupan partes del patrón, esto nos servirá para contar la cantidad de elementos en este grupo\n",
        "#  *** re.finditer() - Busca las coincidencias de la regular expression buscada, pero regresa objetos de coincidencia que entregan más detalles de la misma.\n",
        "#                      En este caso, por ejemplo, nos sirve porque:\n",
        "#                      a) match.group(0) contiene la coincidencia completa '\\w+(!{2,}) para obtener la palabra con sus signos\n",
        "#                      b) match.group(1) contiene la coincidencia del primer grupo capturado (!{2,}) para obtener la cantidad de signos\n",
        "p2 = [(match.group(0), len(match.group(1))) for w in p1 for match in re.finditer(r'\\w+(!{2,})', w)]\n",
        "desplegar_resultados(p2)"
      ],
      "metadata": {
        "id": "0p3kMXfddICc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cecfd1-5845-4336-e05e-6253d5cc21c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 26\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: ('Firehouse!!!!!', 5)\n",
            "[2]: ('APPETIZERS!!!', 3)\n",
            "[3]: ('amazing!!!', 3)\n",
            "[4]: ('buffet!!!', 3)\n",
            "[5]: ('good!!', 2)\n",
            "[6]: ('it!!!!', 4)\n",
            "[7]: ('DELICIOUS!!', 2)\n",
            "[8]: ('amazing!!', 2)\n",
            "[9]: ('shawarrrrrrma!!!!!!', 6)\n",
            "[10]: ('yucky!!!', 3)\n",
            "[11]: ('steak!!!!!', 5)\n",
            "[12]: ('delicious!!!', 3)\n",
            "[13]: ('far!!', 2)\n",
            "[14]: ('biscuits!!!', 3)\n",
            "[15]: ('dry!!', 2)\n",
            "[16]: ('disappointing!!!', 3)\n",
            "[17]: ('awesome!!', 2)\n",
            "[18]: ('Up!!', 2)\n",
            "[19]: ('FLY!!!!!!!!', 8)\n",
            "[20]: ('here!!!', 3)\n",
            "[21]: ('great!!!!!!!!!!!!!!', 14)\n",
            "[22]: ('packed!!', 2)\n",
            "[23]: ('otherwise!!', 2)\n",
            "[24]: ('amazing!!!!!!!!!!!!!!!!!!!', 19)\n",
            "[25]: ('style!!', 2)\n",
            "[26]: ('disappointed!!', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "-s3okBqL96TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p3 contiene una lista con las coincidencias de la búsqueda de palabras completas escritas en mayúsculas\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (for w in p1) recorre la lista p1, mientras que\n",
        "# el segundo ciclo (match for match in re.findall(re, w)) almacenará los resultados en p3 que coincidan\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\b - Indica el inicio y final de la palabra, esto para buscar palabras completas, es decir, que no considere por ejemplo hOOOlaa, pero sí HOOLA\n",
        "#  *** [A-Z]+ - Indica búsqueda conjunto de caracteres en mayúsculas\n",
        "# En esta ocasión, como muchas palabras se repiten, se optó por desplegar los resultados únicos encontrados.\n",
        "p3 = [match for w in p1 for match in re.findall(r'\\b[A-Z]+\\b', w)]\n",
        "desplegar_resultados(p3,unique=True)"
      ],
      "metadata": {
        "id": "yKHJkZKo_nW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e93b999-ec1d-4bd4-f651-f1eddb81313c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 455\n",
            "============================================================\n",
            "Resultados únicos encontrados: 85\n",
            "============================================================\n",
            "[1]: OMG\n",
            "[2]: MANAGEMENT\n",
            "[3]: BETTER\n",
            "[4]: AVOID\n",
            "[5]: NYC\n",
            "[6]: STALE\n",
            "[7]: MANY\n",
            "[8]: RI\n",
            "[9]: TOTAL\n",
            "[10]: FANTASTIC\n",
            "[11]: TOLD\n",
            "[12]: EXPERIENCE\n",
            "[13]: AGAIN\n",
            "[14]: LEGIT\n",
            "[15]: NOT\n",
            "[16]: BBQ\n",
            "[17]: BITCHES\n",
            "[18]: THIS\n",
            "[19]: GC\n",
            "[20]: WHAT\n",
            "[21]: THAT\n",
            "[22]: AZ\n",
            "[23]: BARE\n",
            "[24]: REAL\n",
            "[25]: DELICIOUS\n",
            "[26]: WEAK\n",
            "[27]: WORST\n",
            "[28]: NONE\n",
            "[29]: HAD\n",
            "[30]: HOUR\n",
            "[31]: BACK\n",
            "[32]: AND\n",
            "[33]: AN\n",
            "[34]: GREAT\n",
            "[35]: IT\n",
            "[36]: EVER\n",
            "[37]: UNREAL\n",
            "[38]: RUDE\n",
            "[39]: VERY\n",
            "[40]: HAPPENED\n",
            "[41]: I\n",
            "[42]: HAVE\n",
            "[43]: REALLY\n",
            "[44]: STEP\n",
            "[45]: M\n",
            "[46]: INCONSIDERATE\n",
            "[47]: WASTE\n",
            "[48]: OK\n",
            "[49]: NEVER\n",
            "[50]: CONCLUSION\n",
            "[51]: FREEZING\n",
            "[52]: MGM\n",
            "[53]: THE\n",
            "[54]: AYCE\n",
            "[55]: TV\n",
            "[56]: IN\n",
            "[57]: BARGAIN\n",
            "[58]: NASTY\n",
            "[59]: NO\n",
            "[60]: ALL\n",
            "[61]: A\n",
            "[62]: NOW\n",
            "[63]: T\n",
            "[64]: APPETIZERS\n",
            "[65]: OVERPRICED\n",
            "[66]: OF\n",
            "[67]: FORWARD\n",
            "[68]: TIME\n",
            "[69]: BLAND\n",
            "[70]: LOVED\n",
            "[71]: FLY\n",
            "[72]: PEOPLE\n",
            "[73]: FS\n",
            "[74]: SCREAMS\n",
            "[75]: OWNERS\n",
            "[76]: SHOULD\n",
            "[77]: FLAVOR\n",
            "[78]: WILL\n",
            "[79]: ESTABLISHMENT\n",
            "[80]: HANDS\n",
            "[81]: PERFECT\n",
            "[82]: MUST\n",
            "[83]: GO\n",
            "[84]: WAY\n",
            "[85]: BEST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas.\n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ],
      "metadata": {
        "id": "GX8eYyDoMZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p4 contiene una lista con las coincidencias de la búsqueda de oraciones escritas completamente en mayúsculas\n",
        "# Se utilizará list comprehension\n",
        "# Habrá un ciclo for (s for s in p1 if (re, w)) que agrega a la lista el resultado s (sentence) si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** ^ y $ - Indican inicio y fin del string, respectivamente; por lo que se buscará que la totalidad de la cadena cumpla con el patrón descrito\n",
        "#  *** []+ - Indica una o más repeticiones de los caracteres dentro de los corchetes\n",
        "#  *** A-Z - Se incluyen caracteres alfabéticos en mayúsculas\n",
        "#  *** \\s - Se incluyen espacios\n",
        "#  *** \\d - Se incluyen digitos\n",
        "#  *** \\W - Se incluyen símbolos\n",
        "p4 = [s for s in p1 if re.search(r'^[A-Z\\s\\d\\W]+$', s)]\n",
        "desplegar_resultados(p4)"
      ],
      "metadata": {
        "id": "K8VuZxvTMYj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796c63b8-17d9-4197-d872-f977a8e85fae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 5\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: DELICIOUS!!\n",
            "[2]: RUDE & INCONSIDERATE MANAGEMENT.\n",
            "[3]: WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.\n",
            "[4]: TOTAL WASTE OF TIME.\n",
            "[5]: AVOID THIS ESTABLISHMENT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "a1i6qv7-McmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p5 contiene una lista con las coincidencias de la búsqueda de palabras con alguna vocal con acento.\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\w - Indica que encuentre algún caracter alfanumérico\n",
        "#  *** * - Para que el elemento anterior (caracteres alfanumericos) puede aoarecer cero o más veces\n",
        "#  *** [áéíóúÁÉÍÓÚ] - Seguido de una de las letras acentuadas (se incluyen mayúsculas)\n",
        "#  *** \\w - nuevamente que siga (o no) un caracter alfanumérico\n",
        "#  *** * - Pueden ser varios caracteres alfanuméricos\n",
        "p5 = [match for w in p1 for match in re.findall(r'\\w*[áéíóúÁÉÍÓÚ]\\w*', w)]\n",
        "desplegar_resultados(p5)"
      ],
      "metadata": {
        "id": "nZZ5zKUOMeGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e664e485-7027-4abf-bddb-9f335aefd9e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 3\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: fiancé\n",
            "[2]: Café\n",
            "[3]: puréed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p6 contiene una lista con las coincidencias de la búsqueda de palabras que inician con $, seguidas de un número, ya sea decimal o entero\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\$ - Buscamos el signo de $, sin embargo, se tiene que anteponer la \\ para que no sea tomado como un elemento de regex\n",
        "#  *** \\d+ - Seguido por uno o varios dígitos\n",
        "#  *** (?:...)? - Esta estructura hace que lo que esté dentro de ella sea opcional\n",
        "#  *** \\.\\d+ - Busca el caracter . seguido por 1 o más digitos\n",
        "p6 = [match for w in p1 for match in re.findall(r'\\$\\d+(?:\\.\\d+)?', w)]\n",
        "desplegar_resultados(p6)"
      ],
      "metadata": {
        "id": "6vhe9-Y-MhL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965ecccc-54ff-4f3f-8544-ef2ccba19eb2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 8\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: $20\n",
            "[2]: $4.00\n",
            "[3]: $17\n",
            "[4]: $3\n",
            "[5]: $35\n",
            "[6]: $7.85\n",
            "[7]: $12\n",
            "[8]: $11.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "2j-HpvhwMhq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p7 contiene una lista con las coincidencias de la búsqueda de variantes de la palabra love\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** (?i) - Esta bandera hace que el resultado no sea sensible a mayusculas o minusculas\n",
        "#  *** \\b - Delimita la busqueda para que se garantice que sea al inicio de una palabra\n",
        "#  *** lov - Seguido por las letras lov, que pueden ser tambien Lov lOv LOV, gracias a (?i)\n",
        "#  *** \\w* - Se agrega para buscar cero o más caracteres que, después de lov, crean cualquier conjugación o terminación de la palabra\n",
        "#  *** \\b - Finalizamos con otro delimitador de palabra\n",
        "p7 = [match for w in p1 for match in re.findall(r'(?i)\\blov\\w*\\b', w)]\n",
        "desplegar_resultados(p7, unique=False)"
      ],
      "metadata": {
        "id": "kqqyRChVMjol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8eaf934-5c25-4cd1-da9a-a8ae4a235edb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 36\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: Loved\n",
            "[2]: loved\n",
            "[3]: Loved\n",
            "[4]: love\n",
            "[5]: loves\n",
            "[6]: LOVED\n",
            "[7]: lovers\n",
            "[8]: loving\n",
            "[9]: love\n",
            "[10]: lovers\n",
            "[11]: Love\n",
            "[12]: loved\n",
            "[13]: loved\n",
            "[14]: love\n",
            "[15]: love\n",
            "[16]: love\n",
            "[17]: loved\n",
            "[18]: love\n",
            "[19]: loved\n",
            "[20]: Love\n",
            "[21]: LOVED\n",
            "[22]: love\n",
            "[23]: lovely\n",
            "[24]: love\n",
            "[25]: lovely\n",
            "[26]: love\n",
            "[27]: lover\n",
            "[28]: loved\n",
            "[29]: love\n",
            "[30]: love\n",
            "[31]: love\n",
            "[32]: love\n",
            "[33]: love\n",
            "[34]: love\n",
            "[35]: love\n",
            "[36]: love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good.\n",
        "\n",
        "Indica cuántas encontraste.\n"
      ],
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p8 contiene una lista con las coincidencias de la búsqueda de variantes exageradas de \"so\" y \"good\"\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** (?i) - Deshabilita el modo case-sensitive\n",
        "#  *** (\\b) - Inicio de palabra\n",
        "#  *** s+ - Que tenga una o más s al inicio\n",
        "#  *** oo+ - Que tenga dos o más o\n",
        "#  *** \\b - Fin de palabra\n",
        "#  *** | - Operador OR para incluir las condiciones de otra palabra, en este caso \"good\"\n",
        "#  *** \\b - Inicio de Palabra\n",
        "#  *** g+ - Una o más g al inicio\n",
        "#  *** ooo+ - Tres o más o\n",
        "#  *** d+ - Una o más d\n",
        "#  *** \\b - Fin de palabra\n",
        "p8 = [match for w in p1 for match in re.findall(r'(?i)\\bs+oo+\\b|\\bg+ooo+d+\\b', w)]\n",
        "desplegar_resultados(p8)"
      ],
      "metadata": {
        "id": "A8Nf3B_cMlqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3226cd-dde9-46d7-924f-16518c414f7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 5\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: Sooooo\n",
            "[2]: soooo\n",
            "[3]: gooodd\n",
            "[4]: soooooo\n",
            "[5]: soooo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ],
      "metadata": {
        "id": "hkak1opjMmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p9 contiene una lista con las coincidencias de la búsqueda de variantes exageradas de \"so\" y \"good\"\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\b - Inicio de palabra\n",
        "#  *** [a-zA-Z] - Letras\n",
        "#  *** {11,} - Once o más letras\n",
        "#  *** \\b - Fin de palabra\n",
        "# Nota: Se despliegan solamente resultados únicos encontrados\n",
        "p9 = [match for w in p1 for match in re.findall(r'\\b[a-zA-Z]{11,}\\b', w)]\n",
        "desplegar_resultados(p9,unique=True)"
      ],
      "metadata": {
        "id": "PYxdp3uhMoD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b889aabd-705e-4289-cd24-7255c912d267"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 141\n",
            "============================================================\n",
            "Resultados únicos encontrados: 88\n",
            "============================================================\n",
            "[1]: accordingly\n",
            "[2]: immediately\n",
            "[3]: recommending\n",
            "[4]: Interesting\n",
            "[5]: WAAAAAAyyyyyyyyyy\n",
            "[6]: unbelievable\n",
            "[7]: disappointed\n",
            "[8]: Smashburger\n",
            "[9]: cheeseburger\n",
            "[10]: profiterole\n",
            "[11]: drastically\n",
            "[12]: recommended\n",
            "[13]: unbelievably\n",
            "[14]: disappointment\n",
            "[15]: informative\n",
            "[16]: unexperienced\n",
            "[17]: circumstances\n",
            "[18]: establishment\n",
            "[19]: compliments\n",
            "[20]: transcendant\n",
            "[21]: traditional\n",
            "[22]: enthusiastic\n",
            "[23]: disgraceful\n",
            "[24]: combination\n",
            "[25]: overwhelmed\n",
            "[26]: descriptions\n",
            "[27]: constructed\n",
            "[28]: interesting\n",
            "[29]: imaginative\n",
            "[30]: cheesecurds\n",
            "[31]: anticipated\n",
            "[32]: professional\n",
            "[33]: acknowledged\n",
            "[34]: unprofessional\n",
            "[35]: Disappointing\n",
            "[36]: Unfortunately\n",
            "[37]: extraordinary\n",
            "[38]: imagination\n",
            "[39]: unfortunately\n",
            "[40]: accommodations\n",
            "[41]: disappointing\n",
            "[42]: expectations\n",
            "[43]: maintaining\n",
            "[44]: presentation\n",
            "[45]: INCONSIDERATE\n",
            "[46]: beautifully\n",
            "[47]: inexpensive\n",
            "[48]: Furthermore\n",
            "[49]: Outstanding\n",
            "[50]: ingredients\n",
            "[51]: highlighted\n",
            "[52]: connoisseur\n",
            "[53]: ventilation\n",
            "[54]: disrespected\n",
            "[55]: unsatisfying\n",
            "[56]: opportunity\n",
            "[57]: calligraphy\n",
            "[58]: exceptional\n",
            "[59]: outrageously\n",
            "[60]: recommendation\n",
            "[61]: Disappointed\n",
            "[62]: experienced\n",
            "[63]: deliciously\n",
            "[64]: experiencing\n",
            "[65]: shawarrrrrrma\n",
            "[66]: deuchebaggery\n",
            "[67]: underwhelming\n",
            "[68]: restaurants\n",
            "[69]: suggestions\n",
            "[70]: replenished\n",
            "[71]: reservation\n",
            "[72]: caterpillar\n",
            "[73]: undercooked\n",
            "[74]: corporation\n",
            "[75]: disapppointment\n",
            "[76]: neighborhood\n",
            "[77]: Philadelphia\n",
            "[78]: relationship\n",
            "[79]: Mediterranean\n",
            "[80]: outstanding\n",
            "[81]: hospitality\n",
            "[82]: Wienerschnitzel\n",
            "[83]: ESTABLISHMENT\n",
            "[84]: vinaigrette\n",
            "[85]: comfortable\n",
            "[86]: grandmother\n",
            "[87]: considering\n",
            "[88]: Veggitarian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "ApjTNzSxMpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p10 contiene una lista con las coincidencias de la búsqueda de variantes exageradas de \"so\" y \"good\"\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\s+ - Se busca uno o más espacios, es decir, para que no sea el inicio de la oración\n",
        "#  *** () - Se utilizan para devolver solamente lo que esté dentro de los mismos, pues findall no retorna lo que está fuera, y no queremos el espacio\n",
        "#  *** [A-Z] - Una letra mayúscula\n",
        "#  *** [a-zA-Z]* - Cero o más letras (sin importar mayúsculas o minúsculas), se utiliza * y no + para incluir las palabras de dos letras\n",
        "#  *** [a-z] - Una letra minúscula\n",
        "#  *** \\b - Fin de palabra\n",
        "# Nota: Se despliegan solamente resultados únicos encontrados\n",
        "p10 = [match for w in p1 for match in re.findall(r'\\s+([A-Z][a-zA-Z]*[a-z])\\b', w)]\n",
        "desplegar_resultados(p10,unique=True)"
      ],
      "metadata": {
        "id": "Vb0ndRGAMqdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1931839-cc1e-4d16-dbed-a254f9d16887"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 266\n",
            "============================================================\n",
            "Resultados únicos encontrados: 203\n",
            "============================================================\n",
            "[1]: Mmmm\n",
            "[2]: Lox\n",
            "[3]: Bouchon\n",
            "[4]: Nice\n",
            "[5]: Phoenix\n",
            "[6]: Really\n",
            "[7]: Italian\n",
            "[8]: Plater\n",
            "[9]: Heart\n",
            "[10]: To\n",
            "[11]: Dos\n",
            "[12]: Soi\n",
            "[13]: Rick\n",
            "[14]: Strip\n",
            "[15]: Christmas\n",
            "[16]: Hunan\n",
            "[17]: Place\n",
            "[18]: Heimer\n",
            "[19]: Bachi\n",
            "[20]: Smashburger\n",
            "[21]: Bussell\n",
            "[22]: Mary\n",
            "[23]: Also\n",
            "[24]: Mushroom\n",
            "[25]: Chicken\n",
            "[26]: They\n",
            "[27]: Bisque\n",
            "[28]: Cartel\n",
            "[29]: Gourmet\n",
            "[30]: Las\n",
            "[31]: Sprouts\n",
            "[32]: Taco\n",
            "[33]: Vegas\n",
            "[34]: Our\n",
            "[35]: May\n",
            "[36]: Seat\n",
            "[37]: Maine\n",
            "[38]: Burrittos\n",
            "[39]: When\n",
            "[40]: Customer\n",
            "[41]: Green\n",
            "[42]: Company\n",
            "[43]: Indian\n",
            "[44]: Caballero\n",
            "[45]: Thai\n",
            "[46]: Best\n",
            "[47]: Stars\n",
            "[48]: Sat\n",
            "[49]: Blah\n",
            "[50]: Hiro\n",
            "[51]: Rock\n",
            "[52]: Excalibur\n",
            "[53]: Bellagio\n",
            "[54]: Carly\n",
            "[55]: Soups\n",
            "[56]: Khao\n",
            "[57]: Gordon\n",
            "[58]: Eve\n",
            "[59]: This\n",
            "[60]: Mandalay\n",
            "[61]: Ramsey\n",
            "[62]: Perfect\n",
            "[63]: Nan\n",
            "[64]: Ha\n",
            "[65]: Noca\n",
            "[66]: Palm\n",
            "[67]: Magic\n",
            "[68]: Both\n",
            "[69]: Camelback\n",
            "[70]: Cotta\n",
            "[71]: Breeze\n",
            "[72]: Brushfire\n",
            "[73]: Salads\n",
            "[74]: Steiners\n",
            "[75]: Hard\n",
            "[76]: Eggplant\n",
            "[77]: Large\n",
            "[78]: Halibut\n",
            "[79]: Hut\n",
            "[80]: Pineapple\n",
            "[81]: Sunday\n",
            "[82]: Steak\n",
            "[83]: Cape\n",
            "[84]: Chinese\n",
            "[85]: Jenni\n",
            "[86]: Cibo\n",
            "[87]: Edinburgh\n",
            "[88]: Sushi\n",
            "[89]: Maria\n",
            "[90]: Sour\n",
            "[91]: Yelpers\n",
            "[92]: Casino\n",
            "[93]: Up\n",
            "[94]: Roll\n",
            "[95]: Japanese\n",
            "[96]: Han\n",
            "[97]: Honestly\n",
            "[98]: Rice\n",
            "[99]: Caesar\n",
            "[100]: Steve\n",
            "[101]: Jeff\n",
            "[102]: Panna\n",
            "[103]: Standard\n",
            "[104]: Aria\n",
            "[105]: Buffet\n",
            "[106]: Vegetarian\n",
            "[107]: Great\n",
            "[108]: North\n",
            "[109]: Outstanding\n",
            "[110]: Coffee\n",
            "[111]: Baba\n",
            "[112]: Lobster\n",
            "[113]: Experience\n",
            "[114]: Greek\n",
            "[115]: Hot\n",
            "[116]: Very\n",
            "[117]: Tucson\n",
            "[118]: Risotto\n",
            "[119]: All\n",
            "[120]: Pizza\n",
            "[121]: Pho\n",
            "[122]: Nobu\n",
            "[123]: Elk\n",
            "[124]: Not\n",
            "[125]: Burger\n",
            "[126]: Bean\n",
            "[127]: Food\n",
            "[128]: Egg\n",
            "[129]: Tasty\n",
            "[130]: Toast\n",
            "[131]: Filet\n",
            "[132]: Wife\n",
            "[133]: Cod\n",
            "[134]: Jamaican\n",
            "[135]: Tigerlilly\n",
            "[136]: Mom\n",
            "[137]: Long\n",
            "[138]: Big\n",
            "[139]: Firehouse\n",
            "[140]: Buldogis\n",
            "[141]: Mexican\n",
            "[142]: Kabuki\n",
            "[143]: Ironman\n",
            "[144]: Ganoush\n",
            "[145]: Francisco\n",
            "[146]: Bad\n",
            "[147]: Yama\n",
            "[148]: Luke\n",
            "[149]: Joey\n",
            "[150]: Disappointed\n",
            "[151]: Grill\n",
            "[152]: Fridays\n",
            "[153]: Crystals\n",
            "[154]: Yeah\n",
            "[155]: Prices\n",
            "[156]: Gyros\n",
            "[157]: In\n",
            "[158]: Bay\n",
            "[159]: Valley\n",
            "[160]: English\n",
            "[161]: Frenchman\n",
            "[162]: Pros\n",
            "[163]: Flower\n",
            "[164]: Salad\n",
            "[165]: Area\n",
            "[166]: Loved\n",
            "[167]: San\n",
            "[168]: Sun\n",
            "[169]: Scottsdale\n",
            "[170]: The\n",
            "[171]: Delight\n",
            "[172]: Mellow\n",
            "[173]: Pita\n",
            "[174]: Dog\n",
            "[175]: Magazine\n",
            "[176]: Subway\n",
            "[177]: Lemon\n",
            "[178]: Thumbs\n",
            "[179]: Bar\n",
            "[180]: Shop\n",
            "[181]: Dylan\n",
            "[182]: Otto\n",
            "[183]: Attack\n",
            "[184]: Voodoo\n",
            "[185]: Service\n",
            "[186]: Gringos\n",
            "[187]: Bloody\n",
            "[188]: Macarons\n",
            "[189]: Philadelphia\n",
            "[190]: Costco\n",
            "[191]: Mediterranean\n",
            "[192]: Madison\n",
            "[193]: Chipotle\n",
            "[194]: Wienerschnitzel\n",
            "[195]: Mirage\n",
            "[196]: Mango\n",
            "[197]: Ninja\n",
            "[198]: Albondigas\n",
            "[199]: Paradise\n",
            "[200]: Denny\n",
            "[201]: Ians\n",
            "[202]: Crema\n",
            "[203]: Veggitarian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "u7nfm4KhMrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p11 contiene una lista con las coincidencias de la búsqueda de una o más palabras separadas por guiones.\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** (?i) - Desactiva el modo case sensitive\n",
        "#  *** \\b - Inicio de la palabra\n",
        "#  *** (?:...)+ - Agrupa un conjunto de caracteres y que se repita una o más veces esta secuencia\n",
        "#  *** w+- - Lo que se debe repetir una o más veces es uno o más caracteres alfanuméricos seguidos por un -\n",
        "#  *** \\w+ - Después deberá haber uno o más caracteres alfanuméricos\n",
        "#  *** /b - Fin de la palabra\n",
        "p11 = [match for w in p1 for match in re.findall(r'(?i)\\b(?:\\w+-)+\\w+\\b', w)]\n",
        "desplegar_resultados(p11,unique=False)"
      ],
      "metadata": {
        "id": "OwU-a7eGMsub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a08fb6-1cfe-4641-8d08-d3d63cd758ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 19\n",
            "============================================================\n",
            "Despliegue de resultados:\n",
            "============================================================\n",
            "[1]: flat-lined\n",
            "[2]: hands-down\n",
            "[3]: must-stop\n",
            "[4]: sub-par\n",
            "[5]: Service-check\n",
            "[6]: in-house\n",
            "[7]: been-stepped-in-and-tracked-everywhere\n",
            "[8]: multi-grain\n",
            "[9]: to-go\n",
            "[10]: non-customer\n",
            "[11]: High-quality\n",
            "[12]: sit-down\n",
            "[13]: over-whelm\n",
            "[14]: low-key\n",
            "[15]: non-fancy\n",
            "[16]: golden-crispy\n",
            "[17]: over-priced\n",
            "[18]: over-hip\n",
            "[19]: under-services\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\".\n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ],
      "metadata": {
        "id": "DEIgl79HMthr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p12 contiene una lista con las coincidencias de la búsqueda de palabras que terminan en ing o ed\n",
        "# Se utilizará list comprehension\n",
        "# Habrá dos ciclos for, el primero (match for w in p1) recorrerá todas las palabras en p1\n",
        "# y el segundo (match for match in re.findall(re, w)) que agrega a la lista el resultado match si se cumple\n",
        "# con el parámetro de búsqueda determinado por la expresión regular descrita a continuación:\n",
        "#  *** r'' -  Asume la entrada como una cadena cruda de caracteres (raw)\n",
        "#  *** \\b - Inicio de palabra\n",
        "#  *** \\w+ - Uno o más caracteres alfanuméricos\n",
        "#  *** (?:...) - Creación de un grupo sin captura\n",
        "#  *** ing|ed - Encontrar ya sea ing o ed\n",
        "#  *** \\b - Fin e la palabra\n",
        "# Para desplegar la cantidad de palabras con ing y ed, respectivamente, se utiliza\n",
        "# la instrucción sum(w.endswith('') for w in p12) la cual cuenta la cantidad de\n",
        "# coincidencias de palabras que terminan con los caracteres indicados\n",
        "p12 = [match for w in p1 for match in re.findall(r'\\b\\w+(?:ing|ed)\\b', w)]\n",
        "print(f\"=\"*60)\n",
        "print(f\"Cantidad de palabras con -ing: {sum(w.endswith('ing') for w in p12)}\")\n",
        "print(f\"Cantidad de palabras con -ed: {sum(w.endswith('ed') for w in p12)}\")\n",
        "desplegar_resultados(p12,unique=True)"
      ],
      "metadata": {
        "id": "I4TSofBMMv9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d5621c-942b-47e1-d8fe-6b176d03f384"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Cantidad de palabras con -ing: 279\n",
            "Cantidad de palabras con -ed: 335\n",
            "============================================================\n",
            "Total de resultados encontrados: 614\n",
            "============================================================\n",
            "Resultados únicos encontrados: 300\n",
            "============================================================\n",
            "[1]: covered\n",
            "[2]: seemed\n",
            "[3]: redeeming\n",
            "[4]: missed\n",
            "[5]: expected\n",
            "[6]: disgusting\n",
            "[7]: coming\n",
            "[8]: supposed\n",
            "[9]: focused\n",
            "[10]: recommending\n",
            "[11]: wasting\n",
            "[12]: spring\n",
            "[13]: limited\n",
            "[14]: Tasted\n",
            "[15]: Interesting\n",
            "[16]: rotating\n",
            "[17]: reading\n",
            "[18]: vomited\n",
            "[19]: refused\n",
            "[20]: unwrapped\n",
            "[21]: prepared\n",
            "[22]: forgetting\n",
            "[23]: opposed\n",
            "[24]: Waited\n",
            "[25]: disappointed\n",
            "[26]: charming\n",
            "[27]: falling\n",
            "[28]: dropped\n",
            "[29]: giving\n",
            "[30]: Cooked\n",
            "[31]: wanted\n",
            "[32]: satisfied\n",
            "[33]: surprised\n",
            "[34]: tailored\n",
            "[35]: inviting\n",
            "[36]: drinking\n",
            "[37]: dressing\n",
            "[38]: reminded\n",
            "[39]: upgrading\n",
            "[40]: eating\n",
            "[41]: recommended\n",
            "[42]: listed\n",
            "[43]: rated\n",
            "[44]: refried\n",
            "[45]: included\n",
            "[46]: asked\n",
            "[47]: rolled\n",
            "[48]: closed\n",
            "[49]: witnessed\n",
            "[50]: thing\n",
            "[51]: relocated\n",
            "[52]: unexperienced\n",
            "[53]: craving\n",
            "[54]: flavored\n",
            "[55]: dreamed\n",
            "[56]: Tried\n",
            "[57]: impressed\n",
            "[58]: Pricing\n",
            "[59]: enjoyed\n",
            "[60]: stepped\n",
            "[61]: seating\n",
            "[62]: Ordered\n",
            "[63]: trying\n",
            "[64]: expanded\n",
            "[65]: thrilled\n",
            "[66]: playing\n",
            "[67]: tried\n",
            "[68]: sporting\n",
            "[69]: writing\n",
            "[70]: returning\n",
            "[71]: pricing\n",
            "[72]: judging\n",
            "[73]: reviewing\n",
            "[74]: raving\n",
            "[75]: lacking\n",
            "[76]: flirting\n",
            "[77]: going\n",
            "[78]: handled\n",
            "[79]: making\n",
            "[80]: started\n",
            "[81]: thinking\n",
            "[82]: dining\n",
            "[83]: lighting\n",
            "[84]: toasted\n",
            "[85]: Paying\n",
            "[86]: checked\n",
            "[87]: bring\n",
            "[88]: stuffed\n",
            "[89]: opened\n",
            "[90]: imagined\n",
            "[91]: overwhelmed\n",
            "[92]: changing\n",
            "[93]: powdered\n",
            "[94]: cooked\n",
            "[95]: used\n",
            "[96]: uninspired\n",
            "[97]: having\n",
            "[98]: dealing\n",
            "[99]: rating\n",
            "[100]: fried\n",
            "[101]: interesting\n",
            "[102]: privileged\n",
            "[103]: rushed\n",
            "[104]: constructed\n",
            "[105]: qualified\n",
            "[106]: appealing\n",
            "[107]: owned\n",
            "[108]: talking\n",
            "[109]: uploaded\n",
            "[110]: passed\n",
            "[111]: performed\n",
            "[112]: amazing\n",
            "[113]: priced\n",
            "[114]: anticipated\n",
            "[115]: overcooked\n",
            "[116]: acknowledged\n",
            "[117]: hooked\n",
            "[118]: refreshing\n",
            "[119]: Disappointing\n",
            "[120]: sucked\n",
            "[121]: provided\n",
            "[122]: arrived\n",
            "[123]: hoping\n",
            "[124]: seated\n",
            "[125]: cheated\n",
            "[126]: mixed\n",
            "[127]: ordering\n",
            "[128]: satifying\n",
            "[129]: needed\n",
            "[130]: saying\n",
            "[131]: smeared\n",
            "[132]: disappointing\n",
            "[133]: treated\n",
            "[134]: relaxed\n",
            "[135]: boiled\n",
            "[136]: untoasted\n",
            "[137]: arriving\n",
            "[138]: shopping\n",
            "[139]: dedicated\n",
            "[140]: helped\n",
            "[141]: need\n",
            "[142]: maintaining\n",
            "[143]: living\n",
            "[144]: perpared\n",
            "[145]: ended\n",
            "[146]: saving\n",
            "[147]: burned\n",
            "[148]: looking\n",
            "[149]: stayed\n",
            "[150]: annoying\n",
            "[151]: tasted\n",
            "[152]: outshining\n",
            "[153]: sitting\n",
            "[154]: letting\n",
            "[155]: wrapped\n",
            "[156]: asking\n",
            "[157]: Outstanding\n",
            "[158]: including\n",
            "[159]: claimed\n",
            "[160]: highlighted\n",
            "[161]: dried\n",
            "[162]: tracked\n",
            "[163]: drenched\n",
            "[164]: venturing\n",
            "[165]: inspired\n",
            "[166]: waited\n",
            "[167]: freaking\n",
            "[168]: desired\n",
            "[169]: touched\n",
            "[170]: happened\n",
            "[171]: liked\n",
            "[172]: handed\n",
            "[173]: setting\n",
            "[174]: showed\n",
            "[175]: Stopped\n",
            "[176]: hankering\n",
            "[177]: lined\n",
            "[178]: serving\n",
            "[179]: Everything\n",
            "[180]: seasoning\n",
            "[181]: starving\n",
            "[182]: feeling\n",
            "[183]: disrespected\n",
            "[184]: reheated\n",
            "[185]: humiliated\n",
            "[186]: dipping\n",
            "[187]: working\n",
            "[188]: iced\n",
            "[189]: anything\n",
            "[190]: liking\n",
            "[191]: loved\n",
            "[192]: putting\n",
            "[193]: unsatisfying\n",
            "[194]: drawing\n",
            "[195]: buying\n",
            "[196]: watered\n",
            "[197]: climbing\n",
            "[198]: Coming\n",
            "[199]: charged\n",
            "[200]: wasted\n",
            "[201]: Overpriced\n",
            "[202]: fucking\n",
            "[203]: figured\n",
            "[204]: requested\n",
            "[205]: dusted\n",
            "[206]: during\n",
            "[207]: sliced\n",
            "[208]: eyed\n",
            "[209]: poured\n",
            "[210]: ripped\n",
            "[211]: evening\n",
            "[212]: ensued\n",
            "[213]: received\n",
            "[214]: smelled\n",
            "[215]: dressed\n",
            "[216]: Disappointed\n",
            "[217]: Based\n",
            "[218]: refrained\n",
            "[219]: cramming\n",
            "[220]: looked\n",
            "[221]: handling\n",
            "[222]: appalling\n",
            "[223]: loving\n",
            "[224]: ordered\n",
            "[225]: boring\n",
            "[226]: shocked\n",
            "[227]: experienced\n",
            "[228]: being\n",
            "[229]: disgusted\n",
            "[230]: decided\n",
            "[231]: nothing\n",
            "[232]: experiencing\n",
            "[233]: Loved\n",
            "[234]: pulled\n",
            "[235]: describing\n",
            "[236]: exceeding\n",
            "[237]: staying\n",
            "[238]: packed\n",
            "[239]: doing\n",
            "[240]: attached\n",
            "[241]: underwhelming\n",
            "[242]: located\n",
            "[243]: avoided\n",
            "[244]: greeted\n",
            "[245]: lacked\n",
            "[246]: providing\n",
            "[247]: seasoned\n",
            "[248]: replenished\n",
            "[249]: placed\n",
            "[250]: realized\n",
            "[251]: returned\n",
            "[252]: roasted\n",
            "[253]: red\n",
            "[254]: lived\n",
            "[255]: frustrated\n",
            "[256]: grossed\n",
            "[257]: petrified\n",
            "[258]: insulted\n",
            "[259]: satisfying\n",
            "[260]: running\n",
            "[261]: contained\n",
            "[262]: cooking\n",
            "[263]: editing\n",
            "[264]: missing\n",
            "[265]: caring\n",
            "[266]: undercooked\n",
            "[267]: hated\n",
            "[268]: served\n",
            "[269]: managed\n",
            "[270]: poisoning\n",
            "[271]: added\n",
            "[272]: everything\n",
            "[273]: voted\n",
            "[274]: visited\n",
            "[275]: ignored\n",
            "[276]: building\n",
            "[277]: decorated\n",
            "[278]: filling\n",
            "[279]: outstanding\n",
            "[280]: driving\n",
            "[281]: Nothing\n",
            "[282]: preparing\n",
            "[283]: waiting\n",
            "[284]: revisiting\n",
            "[285]: melted\n",
            "[286]: offered\n",
            "[287]: getting\n",
            "[288]: overpriced\n",
            "[289]: puréed\n",
            "[290]: something\n",
            "[291]: pleased\n",
            "[292]: trimmed\n",
            "[293]: watched\n",
            "[294]: grilled\n",
            "[295]: dripping\n",
            "[296]: walked\n",
            "[297]: screwed\n",
            "[298]: mortified\n",
            "[299]: proclaimed\n",
            "[300]: considering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Resumen de resultados.**  \n",
        "\n",
        "A contuación se presenta una tabla con el resumen de los resultados obtenidos para cada pregunta."
      ],
      "metadata": {
        "id": "kU5wF3_j4--P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo que recorre cada una de las listas con los resultados obtenidos para cada pregunta e imprime su tamaño\n",
        "print(f\"=\"*30)\n",
        "print(f\"Resumen de resultados\")\n",
        "print(f\"=\"*30)\n",
        "for i in range(1, 13):\n",
        "    var_name = f\"p{i}\"\n",
        "    lst = locals().get(var_name)\n",
        "    print(f\"{var_name}: {len(lst)} resultados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miSfHbO0p350",
        "outputId": "bcbc5d47-7157-4375-be17-baf908202df6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Resumen de resultados\n",
            "==============================\n",
            "p1: 1000 resultados\n",
            "p2: 26 resultados\n",
            "p3: 455 resultados\n",
            "p4: 5 resultados\n",
            "p5: 3 resultados\n",
            "p6: 8 resultados\n",
            "p7: 36 resultados\n",
            "p8: 5 resultados\n",
            "p9: 141 resultados\n",
            "p10: 266 resultados\n",
            "p11: 19 resultados\n",
            "p12: 614 resultados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ],
      "metadata": {
        "id": "70StdqAZa9E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes.\n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaDUFXHrMvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Con la expresión re.sub(r'[^A-Za-z\\s]', '', w) se convierten tabs, saltos de línea o espacios dobles en '' (se eliminan)\n",
        "p13 = [re.sub(r'[^A-Za-z\\s]', '', w) for w in p1]\n",
        "\n",
        "# Convertimos a minúsculas\n",
        "p13 = [w.lower() for w in p13]\n",
        "\n",
        "# Reemplazamos tabs, saltos de línea y espacios con ' ' usando la expresión re.sub(r'\\s+', ' ', w)\n",
        "# y con .strip() eliminamos espacios al inicio y al final\n",
        "p13 = [re.sub(r'\\s+', ' ', w).strip() for w in p13]\n",
        "desplegar_resultados(p13,num_resultados=10)"
      ],
      "metadata": {
        "id": "K3kQzPOPMx0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfb7024-d17d-445e-96aa-a26844fee3a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 1000\n",
            "============================================================\n",
            "Primeros 10 Resultados:\n",
            "============================================================\n",
            "[1]: wow loved this place\n",
            "[2]: crust is not good\n",
            "[3]: not tasty and the texture was just nasty\n",
            "[4]: stopped by during the late may bank holiday off rick steve recommendation and loved it\n",
            "[5]: the selection on the menu was great and so were the prices\n",
            "[6]: now i am getting angry and i want my damn pho\n",
            "[7]: honeslty it didnt taste that fresh\n",
            "[8]: the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer\n",
            "[9]: the fries were great too\n",
            "[10]: a great touch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus.\n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus."
      ],
      "metadata": {
        "id": "WZwEhg2lUSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando s.split() dividimos las oraciones en listas de palabras individuales separadas por espacios\n",
        "# Se almacenan las listas en p14 usando list comprehension\n",
        "p14 = [s.split() for s in p13]\n",
        "desplegar_resultados(p14,num_resultados=10)"
      ],
      "metadata": {
        "id": "kbAL9-v0V-jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfa9f95-81a1-432e-d453-e868f2f61a4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Total de resultados encontrados: 1000\n",
            "============================================================\n",
            "Primeros 10 Resultados:\n",
            "============================================================\n",
            "[1]: ['wow', 'loved', 'this', 'place']\n",
            "[2]: ['crust', 'is', 'not', 'good']\n",
            "[3]: ['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty']\n",
            "[4]: ['stopped', 'by', 'during', 'the', 'late', 'may', 'bank', 'holiday', 'off', 'rick', 'steve', 'recommendation', 'and', 'loved', 'it']\n",
            "[5]: ['the', 'selection', 'on', 'the', 'menu', 'was', 'great', 'and', 'so', 'were', 'the', 'prices']\n",
            "[6]: ['now', 'i', 'am', 'getting', 'angry', 'and', 'i', 'want', 'my', 'damn', 'pho']\n",
            "[7]: ['honeslty', 'it', 'didnt', 'taste', 'that', 'fresh']\n",
            "[8]: ['the', 'potatoes', 'were', 'like', 'rubber', 'and', 'you', 'could', 'tell', 'they', 'had', 'been', 'made', 'up', 'ahead', 'of', 'time', 'being', 'kept', 'under', 'a', 'warmer']\n",
            "[9]: ['the', 'fries', 'were', 'great', 'too']\n",
            "[10]: ['a', 'great', 'touch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprime el total de tokens en p14\n",
        "print(f\"Número de tokens: {sum(len(tokens) for tokens in p14)}\")"
      ],
      "metadata": {
        "id": "DZs_etmiV-fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21c21f3-b68a-4035-c782-8e0126ff83b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens: 10777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus.\n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ],
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considera la siguiente lista como tu conjunto de stopwords:\n",
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
      ],
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El resultado p15 es una lista de listas que contienen las palabras sin las stopwords.\n",
        "# Esto se logra ya que se recorre cada lista de tokens dentro de p14 y crea una nueva lista\n",
        "# que sólo conserva aquellos token que no estén en la lista mis_stopwords.\n",
        "p15 = [[token for token in tokens if token not in mis_stopwords] for tokens in p14]\n",
        "\n",
        "# Con sum(len(tokens) for tokens in p15) suma la longitud de cada sublista en p15\n",
        "print(f\"Número de tokens: {sum(len(tokens) for tokens in p15)}\")\n",
        "\n",
        "# Ahora aplastamos todas las sublistas de p15 en un único flujo de tokens y las mete en un set para eliminar duplicados\n",
        "vocabulario = set(token for tokens in p15 for token in tokens)\n",
        "\n",
        "#Se imprime el número de tokens únicos\n",
        "print(f\"Número de tokens únicos: {len(vocabulario)}\")"
      ],
      "metadata": {
        "id": "CD8yjyq1ZrwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9720671-b8a1-406d-eafa-0cead6fcf04d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens: 5776\n",
            "Número de tokens únicos: 1941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ],
      "metadata": {
        "id": "NDbKkuxRbLoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante esta actividad se obtuvo una comprensión empírica sobre el funcionamiento y aplicación de las expresiones regulares, especialmente al realizar búsquedas, formatear, limpiar y analizar conjuntos de oraciones, textos o documentos.\n",
        "\n",
        "Se comprendieron distintas funciones del módulo `re`, como `re.findall()`, `re.search()`, `re.sub()` y `re.finditer()`, además de cuándo es apropiado utilizar cada una de ellas.\n",
        "Algunos ejemplos puntuales para el uso de estas instrucciones son:\n",
        "1. `re.findall()`: Cuando sea necesario obtener todas las coincidencias de un patrón específico, en este trabajo en particular fue útil para la mayoría de los casos, pues buscábamos coincidencias de palabras.\n",
        "\n",
        "2. `re.search()`: Cuando se desea verificar si existe al menos una coincidencia dentro de una cadena, o encontrar la primera aparición. Esto es útil cuando se es de interés analizar toda una oración completa y no dentro de cada palabra en la misma.\n",
        "\n",
        "3. `re.sub()`: Cuando se necesita sustituir coincidencias de un patrón por otra cadena específica.\n",
        "\n",
        "4. `re.finditer()`: Cuando necesites iterar sobre coincidencias, obteniendo información adicional como posiciones exactas o grupos capturados.\n",
        "\n",
        "Por otro lado, se comprendieron los fundamentos de la sintaxis de las expresiones regulares, por lo que comodines y símbolos comunes como `\\w`, `\\d`, `\\n`, `\\b`, `*`, `+` y las agrupaciones mediante `()` ahora son fáciles de identificar dentro de una expresión regular.\n",
        "\n",
        "También se reforzó el manejo de estructuras de datos como listas y su procesamiento mediante *list comprehensions*, destacando su utilidad en tareas relacionadas con procesamiento de texto y lenguaje natural.\n",
        "\n",
        "Queda claro que una limpieza cuidadosa y un buen manejo de los datos de entrada (en este caso, textos) son fundamentales para aplicar eficazmente técnicas de procesamiento de lenguaje natural (NLP) y métodos de aprendizaje automático, incluyendo la tokenización.\n",
        "\n",
        "Finalmente, se logró crear un vocabulario de palabras único a partir de un texto, excluyendo tanto palabras vacías (stopwords) previamente definidas como términos repetidos. Este vocabulario será utilizado posteriormente como entrada para métodos de procesamiento de lenguaje natural.\n"
      ],
      "metadata": {
        "id": "-F_085NZhY1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ],
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      }
    }
  ]
}